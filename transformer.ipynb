{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5471b3c8",
   "metadata": {},
   "source": [
    "References\n",
    "WESAD: https://archive.ics.uci.edu/dataset/465/wesad+wearable+stress+and+affect+detection\n",
    "TabTransformer: https://aravindkolli.medium.com/mastering-tabular-data-with-tabtransformer-a-comprehensive-guide-119f6dbf5a79\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186c9dca",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1. Import Dataset\n",
    "2. Train-test split and Data Loader\n",
    "3. Transformer/ Neural network\n",
    "    1) Create a model\n",
    "    2) Choose a loss function\n",
    "    3) Set an optimizer \n",
    "    4) Run a training loop\n",
    "        Calculate loss (Forward pass)\n",
    "        Compute gradients (Backpropagation)\n",
    "        Updating model parameters\n",
    "4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d47c8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Import Dataset\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "from scipy.stats import mode\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a254112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "041b8679",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WESADDataset(Dataset):\n",
    "    def __init__(self, data_path, window_size=128, overlap=0.0):\n",
    "        self.data_path = data_path\n",
    "        self.window_size = window_size\n",
    "        self.overlap = overlap\n",
    "        self.signal_names = ['ACC','Resp','EDA','Temp','ECG','EMG']  \n",
    "        self.data, self.labels, self.subjects = self.load_dataset()\n",
    "    \n",
    "    def load_dataset(self):\n",
    "        subjects = [f'S{i}' for i in range(1, 18) if i not in [1, 12]]  # S1 and S12 are not available (Problem with sensors)\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "        all_subjects = []\n",
    "        \n",
    "        orig_fs = 700\n",
    "        target_fs = 32\n",
    "        \n",
    "        for subject in subjects:\n",
    "            subj_dir = os.path.join(self.data_path, subject)\n",
    "            data_file = os.path.join(subj_dir, f'{subject}.pkl')\n",
    "            \n",
    "            if not os.path.exists(data_file):\n",
    "                print(f'Warning: {data_file} does not exist')\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                with open(data_file, 'rb') as f:\n",
    "                    raw = torch.load(f) if self.data_path.endswith('.pt') else pickle.load(f, encoding='latin1')\n",
    "                \n",
    "                # Extract chest data and label\n",
    "                chest_data = raw['signal']['chest']\n",
    "                labels = raw['label']\n",
    "                \n",
    "                # Process signals\n",
    "                signals = []\n",
    "                for name in self.signal_names:\n",
    "                    if name in chest_data:\n",
    "                        sig = chest_data[name]\n",
    "                        \n",
    "                        # Handle multi-dimensional signals (like ACC with x,y,z components)\n",
    "                        if len(sig.shape) > 1:\n",
    "                            if name == 'ACC':\n",
    "                                # For accelerometer, compute magnitude from 3D components\n",
    "                                if sig.shape[1] == 3:  # x, y, z components\n",
    "                                    sig = np.sqrt(np.sum(sig**2, axis=1))  # Magnitude\n",
    "                                else:\n",
    "                                    sig = sig.flatten()\n",
    "                            else:\n",
    "                                sig = sig.flatten()\n",
    "                        \n",
    "                        # Resample signal\n",
    "                        sig_resampled = resample(sig, int(len(sig) * target_fs / orig_fs))\n",
    "                        signals.append(sig_resampled)\n",
    "                    else:\n",
    "                        print(f'Warning: {name} missing for {subject}')\n",
    "                \n",
    "                if len(signals) != len(self.signal_names):\n",
    "                    print(f'Skipping {subject} due to missing modalities')\n",
    "                    continue\n",
    "                \n",
    "                # Ensure all signals have same length\n",
    "                min_len = min(map(len, signals))\n",
    "                signals = [s[:min_len] for s in signals]\n",
    "                signal_matrix = np.stack(signals, axis=1)\n",
    "                \n",
    "                # Resample labels\n",
    "                labels_resampled = resample(labels, min_len)\n",
    "                labels_resampled = np.round(labels_resampled).astype(int)\n",
    "                \n",
    "                # Create sliding windows\n",
    "                win_data, win_labels = self.create_windows(signal_matrix, labels_resampled)\n",
    "                \n",
    "                all_data.extend(win_data)\n",
    "                all_labels.extend(win_labels)\n",
    "                all_subjects.extend([subject]*len(win_data))\n",
    "                \n",
    "                print(f'Loaded {len(win_data)} sliding windows for {subject}')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f'Error processing {subject}: {e}')\n",
    "                continue\n",
    "        \n",
    "        return np.array(all_data), np.array(all_labels), np.array(all_subjects)\n",
    "    \n",
    "    def create_windows(self, data, labels):\n",
    "        step = int(self.window_size * (1 - self.overlap))\n",
    "        windows = []\n",
    "        window_labels = []\n",
    "        \n",
    "        for start in range(0, data.shape[0] - self.window_size + 1, step):\n",
    "            end = start + self.window_size\n",
    "            label_window = labels[start:end]\n",
    "            \n",
    "            # Handle newer scipy versions\n",
    "            mode_result = mode(label_window, keepdims=True)\n",
    "            lbl = int(mode_result[0][0])\n",
    "            \n",
    "            if lbl == 1:  # Baseline\n",
    "                windows.append(data[start:end])\n",
    "                window_labels.append(0)\n",
    "            elif lbl == 2:  # Stress\n",
    "                windows.append(data[start:end])\n",
    "                window_labels.append(1)\n",
    "        \n",
    "        return windows, window_labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c60e7697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 440 sliding windows for S2\n",
      "Loaded 445 sliding windows for S3\n",
      "Loaded 449 sliding windows for S4\n",
      "Loaded 460 sliding windows for S5\n",
      "Loaded 458 sliding windows for S6\n",
      "Loaded 457 sliding windows for S7\n",
      "Loaded 460 sliding windows for S8\n",
      "Loaded 456 sliding windows for S9\n",
      "Loaded 476 sliding windows for S10\n",
      "Loaded 465 sliding windows for S11\n",
      "Loaded 461 sliding windows for S13\n",
      "Loaded 464 sliding windows for S14\n",
      "Loaded 464 sliding windows for S15\n",
      "Loaded 463 sliding windows for S16\n",
      "Loaded 476 sliding windows for S17\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = '/Users/kumar/Library/Mobile Documents/com~apple~CloudDocs/Phoenix/OVGU/HiWi2/Tasks/10_WESAD/WESAD.nosync'\n",
    "\n",
    "ds = WESADDataset(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1b6a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window size: How many timesteps or consecutive records each sample contains\n",
    "# Batch size: How many independent samples are processed in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc06ac98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6894\n",
      "128\n",
      "6\n",
      "Input sample: tensor([[ 9.5370e-01,  2.2468e+00,  5.5277e+00,  2.9131e+01, -1.4182e-01,\n",
      "         -6.0475e-03],\n",
      "        [ 9.1147e-01,  2.3274e+00,  5.5262e+00,  2.9136e+01, -1.3497e-01,\n",
      "          6.8507e-05],\n",
      "        [ 9.0827e-01,  2.3982e+00,  5.5229e+00,  2.9145e+01, -9.1329e-02,\n",
      "         -3.4008e-03],\n",
      "        [ 9.2792e-01,  2.4003e+00,  5.5208e+00,  2.9142e+01, -1.2794e-01,\n",
      "          5.1459e-05],\n",
      "        [ 9.3718e-01,  2.4020e+00,  5.5201e+00,  2.9131e+01, -1.3628e-01,\n",
      "         -4.2756e-03],\n",
      "        [ 9.3415e-01,  2.3529e+00,  5.5167e+00,  2.9139e+01, -5.8765e-02,\n",
      "         -2.8011e-03],\n",
      "        [ 9.2376e-01,  2.2870e+00,  5.5171e+00,  2.9137e+01,  7.2924e-02,\n",
      "         -3.5566e-03],\n",
      "        [ 9.2641e-01,  2.2015e+00,  5.5147e+00,  2.9140e+01,  6.3188e-02,\n",
      "         -2.0663e-03],\n",
      "        [ 9.3307e-01,  2.0973e+00,  5.5099e+00,  2.9133e+01,  3.0525e-02,\n",
      "         -2.8087e-03],\n",
      "        [ 9.3486e-01,  1.9369e+00,  5.5108e+00,  2.9139e+01,  1.3204e-02,\n",
      "         -2.8071e-03],\n",
      "        [ 9.2933e-01,  1.7631e+00,  5.5000e+00,  2.9140e+01,  2.2823e-02,\n",
      "         -3.1275e-03],\n",
      "        [ 9.2227e-01,  1.5894e+00,  5.5071e+00,  2.9145e+01,  3.0918e-02,\n",
      "         -1.7953e-03],\n",
      "        [ 9.2795e-01,  1.3780e+00,  5.5033e+00,  2.9135e+01,  2.6511e-02,\n",
      "         -3.2200e-03],\n",
      "        [ 9.2741e-01,  1.1336e+00,  5.5047e+00,  2.9129e+01,  2.5400e-02,\n",
      "         -2.0039e-03],\n",
      "        [ 9.3142e-01,  9.2001e-01,  5.5016e+00,  2.9133e+01,  3.2817e-02,\n",
      "         -2.4560e-03],\n",
      "        [ 9.3158e-01,  6.1808e-01,  5.5032e+00,  2.9136e+01,  1.7588e-02,\n",
      "         -3.9785e-03],\n",
      "        [ 9.3823e-01,  4.0053e-01,  5.4983e+00,  2.9140e+01,  1.7769e-02,\n",
      "         -3.5007e-03],\n",
      "        [ 9.3228e-01,  1.5564e-01,  5.4957e+00,  2.9140e+01,  7.9319e-03,\n",
      "         -1.0183e-03],\n",
      "        [ 9.2586e-01, -8.3471e-02,  5.4955e+00,  2.9133e+01,  8.0591e-03,\n",
      "         -3.0642e-03],\n",
      "        [ 9.2685e-01, -3.0139e-01,  5.4920e+00,  2.9133e+01,  2.5126e-02,\n",
      "         -3.8985e-04],\n",
      "        [ 9.2480e-01, -5.3743e-01,  5.4917e+00,  2.9143e+01,  1.0561e-01,\n",
      "         -4.4146e-03],\n",
      "        [ 9.2867e-01, -7.2979e-01,  5.4885e+00,  2.9140e+01,  4.2990e-02,\n",
      "         -1.9708e-03],\n",
      "        [ 9.3386e-01, -9.3147e-01,  5.4838e+00,  2.9136e+01, -6.3633e-02,\n",
      "         -5.3830e-03],\n",
      "        [ 9.3533e-01, -1.1170e+00,  5.4837e+00,  2.9139e+01,  4.0660e-02,\n",
      "          3.6344e-03],\n",
      "        [ 9.3273e-01, -1.2398e+00,  5.4882e+00,  2.9134e+01,  4.2712e-01,\n",
      "         -7.5649e-03],\n",
      "        [ 9.2777e-01, -1.3732e+00,  5.4806e+00,  2.9155e+01, -1.7439e-02,\n",
      "         -5.4820e-03],\n",
      "        [ 9.2553e-01, -1.4722e+00,  5.4771e+00,  2.9141e+01, -2.2645e-01,\n",
      "          2.0953e-03],\n",
      "        [ 9.2930e-01, -1.5382e+00,  5.4739e+00,  2.9139e+01, -1.7245e-01,\n",
      "         -4.9797e-03],\n",
      "        [ 9.2468e-01, -1.5631e+00,  5.4704e+00,  2.9144e+01, -1.7141e-01,\n",
      "         -1.4562e-03],\n",
      "        [ 9.2818e-01, -1.5494e+00,  5.4668e+00,  2.9137e+01, -1.3465e-01,\n",
      "         -4.0458e-03],\n",
      "        [ 9.3386e-01, -1.5544e+00,  5.4642e+00,  2.9145e+01, -1.8441e-01,\n",
      "         -1.0279e-03],\n",
      "        [ 9.3041e-01, -1.4492e+00,  5.4596e+00,  2.9137e+01, -1.7289e-01,\n",
      "         -5.1192e-03],\n",
      "        [ 9.2678e-01, -1.3758e+00,  5.4578e+00,  2.9140e+01, -7.1046e-02,\n",
      "         -2.5904e-03],\n",
      "        [ 9.2393e-01, -1.2194e+00,  5.4565e+00,  2.9144e+01,  5.8989e-02,\n",
      "         -2.8639e-03],\n",
      "        [ 9.2601e-01, -1.0923e+00,  5.4494e+00,  2.9143e+01,  2.6188e-02,\n",
      "         -2.2362e-03],\n",
      "        [ 9.2795e-01, -9.3744e-01,  5.4489e+00,  2.9146e+01,  1.5496e-02,\n",
      "         -2.6375e-03],\n",
      "        [ 9.3092e-01, -7.2469e-01,  5.4429e+00,  2.9140e+01, -9.5544e-03,\n",
      "         -2.9184e-03],\n",
      "        [ 9.2622e-01, -5.1307e-01,  5.4412e+00,  2.9142e+01,  1.9386e-02,\n",
      "         -3.1979e-03],\n",
      "        [ 9.3054e-01, -2.9416e-01,  5.4368e+00,  2.9144e+01,  7.0839e-03,\n",
      "         -9.9177e-04],\n",
      "        [ 9.2858e-01, -4.5899e-02,  5.4337e+00,  2.9142e+01,  1.1753e-02,\n",
      "         -4.2418e-03],\n",
      "        [ 9.2772e-01,  1.9366e-01,  5.4273e+00,  2.9152e+01,  8.2535e-04,\n",
      "         -1.7768e-03],\n",
      "        [ 9.2868e-01,  4.7644e-01,  5.4286e+00,  2.9143e+01,  1.8235e-02,\n",
      "         -4.7033e-03],\n",
      "        [ 9.2773e-01,  7.0185e-01,  5.4251e+00,  2.9151e+01, -9.9973e-03,\n",
      "         -9.7530e-04],\n",
      "        [ 9.3240e-01,  9.6962e-01,  5.4220e+00,  2.9135e+01,  2.5259e-02,\n",
      "         -5.3561e-03],\n",
      "        [ 9.2510e-01,  1.2923e+00,  5.4182e+00,  2.9144e+01, -7.8287e-03,\n",
      "         -1.6298e-03],\n",
      "        [ 9.2612e-01,  1.5588e+00,  5.4167e+00,  2.9139e+01,  9.3687e-02,\n",
      "         -3.1720e-03],\n",
      "        [ 9.3136e-01,  1.8347e+00,  5.4141e+00,  2.9141e+01,  7.7938e-02,\n",
      "         -3.2325e-03],\n",
      "        [ 9.2983e-01,  2.1281e+00,  5.4120e+00,  2.9140e+01, -5.0303e-03,\n",
      "         -4.4098e-03],\n",
      "        [ 9.2858e-01,  2.3760e+00,  5.4101e+00,  2.9139e+01, -6.0930e-02,\n",
      "          1.0848e-03],\n",
      "        [ 9.2613e-01,  2.6102e+00,  5.4078e+00,  2.9138e+01,  2.4560e-01,\n",
      "         -2.7127e-03],\n",
      "        [ 9.3011e-01,  2.8307e+00,  5.4063e+00,  2.9146e+01,  2.4641e-01,\n",
      "         -9.7966e-03],\n",
      "        [ 9.3405e-01,  3.0473e+00,  5.4055e+00,  2.9146e+01, -1.5378e-01,\n",
      "          2.0124e-03],\n",
      "        [ 9.2690e-01,  3.2344e+00,  5.3996e+00,  2.9158e+01, -1.5046e-01,\n",
      "         -4.2620e-03],\n",
      "        [ 9.2556e-01,  3.4168e+00,  5.4004e+00,  2.9145e+01, -1.2950e-01,\n",
      "         -7.8114e-04],\n",
      "        [ 9.2672e-01,  3.5337e+00,  5.3980e+00,  2.9152e+01, -1.0195e-01,\n",
      "         -4.3873e-03],\n",
      "        [ 9.3605e-01,  3.6656e+00,  5.3948e+00,  2.9153e+01, -1.0251e-01,\n",
      "         -2.1183e-03],\n",
      "        [ 9.3625e-01,  3.7671e+00,  5.3980e+00,  2.9148e+01, -1.3085e-01,\n",
      "         -1.3010e-03],\n",
      "        [ 9.2546e-01,  3.8620e+00,  5.3953e+00,  2.9151e+01, -7.7351e-02,\n",
      "         -5.3071e-03],\n",
      "        [ 9.1851e-01,  3.8915e+00,  5.3953e+00,  2.9146e+01,  5.0828e-02,\n",
      "         -1.2735e-03],\n",
      "        [ 9.2913e-01,  3.9232e+00,  5.3927e+00,  2.9147e+01,  8.4372e-02,\n",
      "         -1.7768e-03],\n",
      "        [ 9.3059e-01,  3.9328e+00,  5.3901e+00,  2.9144e+01,  4.8343e-02,\n",
      "         -3.3394e-03],\n",
      "        [ 9.3230e-01,  3.9692e+00,  5.3879e+00,  2.9153e+01,  4.4173e-02,\n",
      "         -2.0874e-03],\n",
      "        [ 9.2814e-01,  3.9305e+00,  5.3870e+00,  2.9149e+01,  2.5079e-02,\n",
      "         -2.1963e-03],\n",
      "        [ 9.2478e-01,  3.9048e+00,  5.3850e+00,  2.9149e+01,  3.3570e-02,\n",
      "         -3.0172e-03],\n",
      "        [ 9.2708e-01,  3.8148e+00,  5.3861e+00,  2.9149e+01,  1.9724e-02,\n",
      "         -1.5263e-03],\n",
      "        [ 9.2846e-01,  3.7635e+00,  5.3826e+00,  2.9158e+01,  2.5118e-02,\n",
      "         -4.0933e-03],\n",
      "        [ 9.2581e-01,  3.6901e+00,  5.3824e+00,  2.9145e+01,  1.4667e-02,\n",
      "         -2.9790e-03],\n",
      "        [ 9.2583e-01,  3.5927e+00,  5.3815e+00,  2.9155e+01,  1.3739e-02,\n",
      "         -2.0536e-03],\n",
      "        [ 9.2423e-01,  3.4719e+00,  5.3811e+00,  2.9150e+01,  2.6259e-02,\n",
      "         -4.3870e-03],\n",
      "        [ 9.3004e-01,  3.4099e+00,  5.3813e+00,  2.9146e+01,  1.3406e-01,\n",
      "         -2.4613e-03],\n",
      "        [ 9.2382e-01,  3.3103e+00,  5.3802e+00,  2.9156e+01,  5.4915e-02,\n",
      "         -2.4785e-03],\n",
      "        [ 9.3032e-01,  3.2277e+00,  5.3743e+00,  2.9158e+01, -3.7475e-02,\n",
      "         -6.8524e-03],\n",
      "        [ 9.3651e-01,  3.1079e+00,  5.3754e+00,  2.9158e+01,  9.9262e-03,\n",
      "          2.9890e-03],\n",
      "        [ 9.1922e-01,  3.0281e+00,  5.3792e+00,  2.9147e+01,  4.0852e-01,\n",
      "         -7.8380e-03],\n",
      "        [ 9.3182e-01,  2.9786e+00,  5.3798e+00,  2.9143e+01,  3.5816e-02,\n",
      "         -7.3622e-03],\n",
      "        [ 9.2993e-01,  2.8615e+00,  5.3737e+00,  2.9152e+01, -1.8606e-01,\n",
      "          2.5580e-03],\n",
      "        [ 9.2439e-01,  2.7904e+00,  5.3723e+00,  2.9154e+01, -1.7015e-01,\n",
      "         -4.3733e-03],\n",
      "        [ 9.3288e-01,  2.7259e+00,  5.3669e+00,  2.9149e+01, -1.4253e-01,\n",
      "          4.8742e-04],\n",
      "        [ 9.3164e-01,  2.6621e+00,  5.3696e+00,  2.9153e+01, -1.0674e-01,\n",
      "         -6.9217e-03],\n",
      "        [ 9.2670e-01,  2.5850e+00,  5.3666e+00,  2.9151e+01, -1.1957e-01,\n",
      "         -8.6126e-04],\n",
      "        [ 9.3476e-01,  2.5166e+00,  5.3656e+00,  2.9147e+01, -1.3886e-01,\n",
      "         -3.2004e-03],\n",
      "        [ 9.3342e-01,  2.4902e+00,  5.3663e+00,  2.9150e+01, -2.9015e-02,\n",
      "         -3.3996e-03],\n",
      "        [ 9.2838e-01,  2.4552e+00,  5.3658e+00,  2.9142e+01,  6.4753e-02,\n",
      "         -1.7521e-03],\n",
      "        [ 9.1982e-01,  2.3929e+00,  5.3605e+00,  2.9144e+01,  7.2989e-02,\n",
      "         -1.1824e-03],\n",
      "        [ 9.2786e-01,  2.3768e+00,  5.3650e+00,  2.9146e+01,  3.8600e-02,\n",
      "         -5.0861e-03],\n",
      "        [ 9.3320e-01,  2.3537e+00,  5.3675e+00,  2.9144e+01,  5.2281e-02,\n",
      "         -8.6707e-04],\n",
      "        [ 9.2748e-01,  2.2809e+00,  5.3710e+00,  2.9148e+01,  3.4575e-02,\n",
      "         -2.8968e-03],\n",
      "        [ 9.3422e-01,  2.2189e+00,  5.3707e+00,  2.9143e+01,  5.4608e-02,\n",
      "         -2.2313e-03],\n",
      "        [ 9.2910e-01,  2.2363e+00,  5.3699e+00,  2.9143e+01,  1.9783e-02,\n",
      "         -4.0577e-03],\n",
      "        [ 9.2634e-01,  2.1763e+00,  5.3693e+00,  2.9146e+01,  4.4835e-02,\n",
      "         -1.1691e-03],\n",
      "        [ 9.2709e-01,  2.1305e+00,  5.3694e+00,  2.9147e+01,  9.5954e-03,\n",
      "         -3.9677e-03],\n",
      "        [ 9.2602e-01,  2.0736e+00,  5.3665e+00,  2.9142e+01,  9.9458e-02,\n",
      "          6.8472e-05],\n",
      "        [ 9.2556e-01,  2.0332e+00,  5.3696e+00,  2.9141e+01,  1.2476e-01,\n",
      "         -3.4665e-03],\n",
      "        [ 9.2637e-01,  1.9848e+00,  5.3667e+00,  2.9146e+01,  5.6699e-02,\n",
      "         -1.7735e-03],\n",
      "        [ 9.2720e-01,  1.9617e+00,  5.3623e+00,  2.9146e+01, -1.1250e-01,\n",
      "         -4.7628e-03],\n",
      "        [ 9.3389e-01,  1.9159e+00,  5.3663e+00,  2.9145e+01,  2.2309e-01,\n",
      "          4.2860e-03],\n",
      "        [ 9.2542e-01,  1.8623e+00,  5.3685e+00,  2.9148e+01,  4.9225e-01,\n",
      "         -1.0138e-02],\n",
      "        [ 9.2918e-01,  1.8300e+00,  5.3651e+00,  2.9151e+01, -1.8433e-01,\n",
      "         -9.9069e-04],\n",
      "        [ 9.3221e-01,  1.7686e+00,  5.3597e+00,  2.9142e+01, -1.9098e-01,\n",
      "         -1.4657e-03],\n",
      "        [ 9.1826e-01,  1.7245e+00,  5.3572e+00,  2.9150e+01, -2.0465e-01,\n",
      "         -1.7910e-03],\n",
      "        [ 9.1946e-01,  1.7372e+00,  5.3566e+00,  2.9146e+01, -1.3523e-01,\n",
      "         -2.2171e-03],\n",
      "        [ 9.3449e-01,  1.6670e+00,  5.3539e+00,  2.9152e+01, -1.4246e-01,\n",
      "         -2.9876e-03],\n",
      "        [ 9.3692e-01,  1.6652e+00,  5.3522e+00,  2.9144e+01, -1.5284e-01,\n",
      "         -2.6084e-03],\n",
      "        [ 9.2737e-01,  1.6272e+00,  5.3512e+00,  2.9145e+01, -1.4004e-01,\n",
      "         -2.3201e-03],\n",
      "        [ 9.2560e-01,  1.5848e+00,  5.3490e+00,  2.9146e+01, -8.6974e-03,\n",
      "         -3.2032e-03],\n",
      "        [ 9.2972e-01,  1.5354e+00,  5.3516e+00,  2.9140e+01,  4.0476e-02,\n",
      "         -2.5758e-03],\n",
      "        [ 9.2297e-01,  1.5250e+00,  5.3462e+00,  2.9144e+01,  1.3877e-02,\n",
      "         -1.7152e-03],\n",
      "        [ 9.3024e-01,  1.4874e+00,  5.3442e+00,  2.9151e+01,  1.9308e-02,\n",
      "         -1.8711e-03],\n",
      "        [ 9.3900e-01,  1.4706e+00,  5.3431e+00,  2.9147e+01, -3.2389e-03,\n",
      "         -2.7212e-03],\n",
      "        [ 9.2893e-01,  1.3996e+00,  5.3401e+00,  2.9147e+01,  1.5001e-02,\n",
      "         -3.3622e-03],\n",
      "        [ 9.2685e-01,  1.3364e+00,  5.3400e+00,  2.9145e+01,  5.8320e-03,\n",
      "         -2.7422e-03],\n",
      "        [ 9.2674e-01,  1.3260e+00,  5.3387e+00,  2.9144e+01,  2.3325e-02,\n",
      "         -2.2890e-03],\n",
      "        [ 9.2469e-01,  1.2833e+00,  5.3344e+00,  2.9146e+01, -2.2799e-02,\n",
      "         -2.6675e-03],\n",
      "        [ 9.2793e-01,  1.2411e+00,  5.3324e+00,  2.9139e+01,  1.0300e-01,\n",
      "         -3.2363e-03],\n",
      "        [ 9.2798e-01,  1.1937e+00,  5.3325e+00,  2.9150e+01,  9.9305e-02,\n",
      "         -5.8328e-03],\n",
      "        [ 9.3000e-01,  1.1303e+00,  5.3267e+00,  2.9157e+01, -4.0260e-03,\n",
      "         -1.1226e-04],\n",
      "        [ 9.2951e-01,  1.0696e+00,  5.3273e+00,  2.9146e+01, -1.3085e-01,\n",
      "         -6.6852e-04],\n",
      "        [ 9.2652e-01,  1.0139e+00,  5.3260e+00,  2.9149e+01,  3.5436e-01,\n",
      "         -2.8464e-05],\n",
      "        [ 9.3053e-01,  9.4570e-01,  5.3280e+00,  2.9149e+01,  2.8699e-01,\n",
      "         -1.0285e-02],\n",
      "        [ 9.2807e-01,  8.8047e-01,  5.3264e+00,  2.9150e+01, -2.6713e-01,\n",
      "         -1.8465e-04],\n",
      "        [ 9.3335e-01,  8.4490e-01,  5.3210e+00,  2.9141e+01, -1.7231e-01,\n",
      "         -2.5964e-03],\n",
      "        [ 9.2799e-01,  7.4593e-01,  5.3205e+00,  2.9150e+01, -2.0877e-01,\n",
      "         -3.3760e-03],\n",
      "        [ 9.2161e-01,  7.0666e-01,  5.3206e+00,  2.9152e+01, -1.1553e-01,\n",
      "         -3.7251e-03],\n",
      "        [ 9.3624e-01,  6.9003e-01,  5.3176e+00,  2.9146e+01, -1.6939e-01,\n",
      "         -9.1883e-04],\n",
      "        [ 9.3351e-01,  5.7882e-01,  5.3165e+00,  2.9155e+01, -1.4562e-01,\n",
      "         -2.8399e-03],\n",
      "        [ 9.2846e-01,  5.4453e-01,  5.3183e+00,  2.9154e+01, -1.4330e-01,\n",
      "         -3.8479e-03],\n",
      "        [ 9.2482e-01,  4.7605e-01,  5.3164e+00,  2.9145e+01,  2.7542e-02,\n",
      "         -3.6684e-03],\n",
      "        [ 9.2480e-01,  4.4571e-01,  5.3136e+00,  2.9156e+01,  2.9194e-02,\n",
      "         -1.5195e-03]])\n",
      "Label sample: tensor(0)\n"
     ]
    }
   ],
   "source": [
    "print(len(ds)) # How 6894?, all devices sampled at same rate?\n",
    "input_sample, label_sample = ds[0]\n",
    "print(len(input_sample)) # Time steps = 128, (window size is downsampled from 700 Hz to 32Hz, 128/32 = 4 seconds of data per window)\n",
    "print(len(input_sample[0])) # ['ACC','Resp','EDA','Temp','ECG','EMG'], 6 sensors\n",
    "print('Input sample:', input_sample) # 128 * 6\n",
    "print('Label sample:', label_sample) # 0 for Baseline, 1 for Stress label for 4 seconds window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8400f0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6894 5515 1379\n"
     ]
    }
   ],
   "source": [
    "# 2. Train test size\n",
    "\n",
    "total_size = len(ds)\n",
    "train_size = int(0.8 * total_size)\n",
    "test_size = total_size - train_size\n",
    "\n",
    "print(total_size, train_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65a51fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "train_dataset, test_dataset = random_split(ds, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe6b8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_inputs: tensor([[[ 9.2007e-01, -2.8284e+00,  9.7674e-01,  3.3479e+01,  2.1780e-03,\n",
      "           2.7065e-04],\n",
      "         [ 9.2262e-01, -2.8378e+00,  9.7203e-01,  3.3481e+01,  2.3069e-01,\n",
      "          -2.5320e-03],\n",
      "         [ 9.1597e-01, -2.8122e+00,  9.7693e-01,  3.3481e+01,  3.4513e-02,\n",
      "          -2.8421e-03],\n",
      "         ...,\n",
      "         [ 9.2315e-01, -2.0387e+00,  9.7202e-01,  3.3490e+01, -1.0022e-01,\n",
      "          -7.5321e-04],\n",
      "         [ 9.2305e-01, -1.5831e+00,  9.6687e-01,  3.3490e+01, -8.3052e-02,\n",
      "          -3.1608e-03],\n",
      "         [ 9.1957e-01, -1.0806e+00,  9.7507e-01,  3.3496e+01,  1.1131e-01,\n",
      "          -2.7328e-03]],\n",
      "\n",
      "        [[ 9.2322e-01, -4.2017e-01,  6.5789e+00,  3.1325e+01,  1.2491e+00,\n",
      "          -9.6817e-03],\n",
      "         [ 9.2234e-01, -3.8646e-01,  6.5784e+00,  3.1323e+01,  4.0112e-02,\n",
      "           4.4220e-03],\n",
      "         [ 9.2543e-01, -3.5589e-01,  6.5765e+00,  3.1324e+01, -1.8671e-01,\n",
      "          -4.4127e-03],\n",
      "         ...,\n",
      "         [ 9.2726e-01, -1.1159e+00,  6.5904e+00,  3.1329e+01, -1.6193e-01,\n",
      "          -1.5135e-03],\n",
      "         [ 9.2279e-01, -1.0834e+00,  6.5868e+00,  3.1330e+01, -3.5386e-01,\n",
      "          -4.1381e-03],\n",
      "         [ 9.2478e-01, -1.0322e+00,  6.5825e+00,  3.1330e+01, -3.2118e-01,\n",
      "          -2.1080e-03]],\n",
      "\n",
      "        [[ 9.2663e-01,  3.3288e+00,  3.4844e+00,  3.4522e+01, -1.4378e-01,\n",
      "          -3.5200e-03],\n",
      "         [ 9.3587e-01,  3.5464e+00,  3.4864e+00,  3.4522e+01, -1.3035e-01,\n",
      "          -1.0228e-03],\n",
      "         [ 9.2823e-01,  3.7240e+00,  3.4860e+00,  3.4519e+01, -5.7492e-02,\n",
      "          -4.0730e-03],\n",
      "         ...,\n",
      "         [ 9.3560e-01, -1.3472e+00,  3.4887e+00,  3.4520e+01, -2.2770e-01,\n",
      "          -1.3018e-03],\n",
      "         [ 9.3544e-01, -1.1173e+00,  3.4831e+00,  3.4532e+01, -1.4429e-01,\n",
      "          -3.6101e-03],\n",
      "         [ 9.2760e-01, -8.5552e-01,  3.4874e+00,  3.4516e+01, -5.9457e-02,\n",
      "          -4.9615e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 9.2786e-01, -1.6809e+00,  2.9310e+00,  3.4334e+01, -7.4009e-02,\n",
      "          -1.4421e-03],\n",
      "         [ 9.4110e-01, -1.7258e+00,  2.9301e+00,  3.4332e+01,  2.0811e-03,\n",
      "          -1.8265e-03],\n",
      "         [ 9.3823e-01, -1.7899e+00,  2.9292e+00,  3.4326e+01, -2.2698e-01,\n",
      "          -2.9441e-03],\n",
      "         ...,\n",
      "         [ 9.3562e-01, -4.1450e+00,  2.9298e+00,  3.4325e+01, -1.6611e-01,\n",
      "          -2.4671e-03],\n",
      "         [ 9.3964e-01, -4.1968e+00,  2.9306e+00,  3.4335e+01, -1.2095e-01,\n",
      "          -4.2407e-03],\n",
      "         [ 9.3218e-01, -4.2456e+00,  2.9280e+00,  3.4328e+01, -5.3943e-01,\n",
      "          -1.3835e-03]],\n",
      "\n",
      "        [[ 9.4528e-01,  2.8043e+00,  3.8004e+00,  3.5006e+01,  2.5297e-03,\n",
      "          -5.9057e-04],\n",
      "         [ 9.4842e-01,  2.7316e+00,  3.7987e+00,  3.4999e+01,  4.3667e-02,\n",
      "          -4.3505e-03],\n",
      "         [ 9.4700e-01,  2.6773e+00,  3.7978e+00,  3.5003e+01,  9.2827e-03,\n",
      "          -1.7645e-03],\n",
      "         ...,\n",
      "         [ 9.4530e-01,  2.5426e+00,  3.7981e+00,  3.4943e+01, -2.2350e-01,\n",
      "          -2.9394e-03],\n",
      "         [ 9.4638e-01,  2.3993e+00,  3.7992e+00,  3.4954e+01,  1.0943e-02,\n",
      "          -6.1299e-03],\n",
      "         [ 9.4528e-01,  2.2672e+00,  3.8005e+00,  3.4951e+01, -1.2457e-01,\n",
      "          -1.4073e-03]],\n",
      "\n",
      "        [[ 9.1971e-01, -2.4240e+00,  6.0011e+00,  3.4125e+01, -1.6539e-01,\n",
      "          -1.2244e-03],\n",
      "         [ 9.2269e-01, -2.4871e+00,  6.0013e+00,  3.4124e+01,  1.0111e+00,\n",
      "          -7.9947e-03],\n",
      "         [ 9.2271e-01, -2.5582e+00,  6.0117e+00,  3.4123e+01, -1.3899e-01,\n",
      "           7.1508e-05],\n",
      "         ...,\n",
      "         [ 9.1590e-01, -2.4883e+00,  5.9985e+00,  3.4152e+01, -5.7341e-02,\n",
      "          -3.5102e-03],\n",
      "         [ 9.1546e-01, -2.5123e+00,  5.9976e+00,  3.4143e+01,  1.9254e-02,\n",
      "          -3.2772e-03],\n",
      "         [ 9.1613e-01, -2.5393e+00,  5.9984e+00,  3.4158e+01, -4.7685e-02,\n",
      "          -3.1265e-03]]])\n",
      "batch_labels: tensor([0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0])\n",
      "32\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# Data Loaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle = True) # batch size = grouping 32 samples\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = 32, shuffle = True)\n",
    "\n",
    "# Sample batch\n",
    "for batch_inputs, batch_labels in train_dataloader:\n",
    "    print('batch_inputs:', batch_inputs)\n",
    "    print('batch_labels:', batch_labels)\n",
    "    print(len(batch_inputs))\n",
    "    print(len(batch_inputs[0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce06bd2",
   "metadata": {},
   "source": [
    "3. Transformer/ Neural network\n",
    "    1) Create a model\n",
    "    2) Choose a loss function\n",
    "    3) Define a dataset\n",
    "    4) Set an optimizer \n",
    "    5) Run a training loop\n",
    "        Calculate loss (Forward pass)\n",
    "        Compute gradients (Backpropagation)\n",
    "        Updating model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac404f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is scaling required?\n",
    "# num_heads = width of attention (how many perspectives are considered in parallel).\n",
    "# num_layers = depth of reasoning (how many times the model refines its understanding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854743c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 TabTransformer model class, modified from Medium\n",
    "\n",
    "class TabTransformer(nn.Module):\n",
    "    def __init__(self, num_features, num_classes, dim_embedding, num_heads, num_layers):\n",
    "        super(TabTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(num_features, dim_embedding) # project input features -> embedding\n",
    "        # transformer encoder (batch_first=True so input shape is [batch_size, timesteps, num_features/dim_embedding])\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=dim_embedding,nhead=num_heads,dim_feedforward=dim_embedding * 4,batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.classifier = nn.Linear(dim_embedding, num_classes) # simple linear classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch, timesteps, features]\n",
    "        x = self.embedding(x)            # -> [batch, timesteps, dim_embedding], project input to embedding\n",
    "        x = self.transformer(x)          # -> [batch, timesteps, dim_embedding], passes through multiple [Attention + FFN + Norm] layers\n",
    "        x = torch.mean(x, dim=1)         # -> [batch, dim_embedding], global mean pooling over timesteps \n",
    "        x = self.classifier(x)           # -> [batch, num_classes], final classification head\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a054a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabTransformer(\n",
      "  (embedding): Linear(in_features=6, out_features=64, bias=True)\n",
      "  (transformer): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=64, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
      "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = TabTransformer(\n",
    "    num_features = 6,        # 6 sensor features\n",
    "    num_classes = 2,         # Binary classification\n",
    "    dim_embedding = 64,      # Embedding dimension\n",
    "    num_heads = 4,           # Number of attention heads\n",
    "    num_layers = 4,          # Number of transformer layers\n",
    ").to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33098ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function criterion and optimizer \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.004)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbb7b872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional libraries\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdbb88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train_tensor)\n",
    "    loss = criterion(output, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
