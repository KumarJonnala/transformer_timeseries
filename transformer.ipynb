{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5471b3c8",
   "metadata": {},
   "source": [
    "References\n",
    "WESAD: https://archive.ics.uci.edu/dataset/465/wesad+wearable+stress+and+affect+detection \\\n",
    "TabTransformer:\\\n",
    "https://aravindkolli.medium.com/mastering-tabular-data-with-tabtransformer-a-comprehensive-guide-119f6dbf5a79 \\\n",
    "https://medium.com/@cristianleo120/the-math-behind-tabtransformer-78b78c12cfc1 \\\n",
    "https://towardsdatascience.com/transformers-for-tabular-data-b3e196fab6f4/\\\n",
    "https://towardsdatascience.com/transformers-for-tabular-data-tabtransformer-deep-dive-5fb2438da820/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186c9dca",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1. Import Dataset\n",
    "2. Train-test split and Data Loader\n",
    "3. Transformer/ Neural network\n",
    "    1) Create a model\n",
    "    2) Choose a loss function\n",
    "    3) Set an optimizer \n",
    "    4) Run a training loop\n",
    "        Calculate loss (Forward pass)\n",
    "        Compute gradients (Backpropagation)\n",
    "        Updating model parameters\n",
    "4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d47c8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Import Dataset\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "from scipy.stats import mode\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a254112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, Subset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "041b8679",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WESADDataset(Dataset):\n",
    "    def __init__(self, data_path, window_size=128, overlap=0.0):\n",
    "        self.data_path = data_path\n",
    "        self.window_size = window_size\n",
    "        self.overlap = overlap\n",
    "        self.signal_names = ['ACC','Resp','EDA','Temp','ECG','EMG']  \n",
    "        self.data, self.labels, self.subjects = self.load_dataset()\n",
    "    \n",
    "    def load_dataset(self):\n",
    "        subjects = [f'S{i}' for i in range(1, 18) if i not in [1, 12]]  # S1 and S12 are not available (Problem with sensors)\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "        all_subjects = []\n",
    "        \n",
    "        orig_fs = 700\n",
    "        target_fs = 32\n",
    "        \n",
    "        for subject in subjects:\n",
    "            subj_dir = os.path.join(self.data_path, subject)\n",
    "            data_file = os.path.join(subj_dir, f'{subject}.pkl')\n",
    "            \n",
    "            if not os.path.exists(data_file):\n",
    "                print(f'Warning: {data_file} does not exist')\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                with open(data_file, 'rb') as f:\n",
    "                    raw = torch.load(f) if self.data_path.endswith('.pt') else pickle.load(f, encoding='latin1')\n",
    "                \n",
    "                # Extract chest data and label\n",
    "                chest_data = raw['signal']['chest']\n",
    "                labels = raw['label']\n",
    "                \n",
    "                # Process signals\n",
    "                signals = []\n",
    "                for name in self.signal_names:\n",
    "                    if name in chest_data:\n",
    "                        sig = chest_data[name]\n",
    "                        \n",
    "                        # Handle multi-dimensional signals (like ACC with x,y,z components)\n",
    "                        if len(sig.shape) > 1:\n",
    "                            if name == 'ACC':\n",
    "                                # For accelerometer, compute magnitude from 3D components\n",
    "                                if sig.shape[1] == 3:  # x, y, z components\n",
    "                                    sig = np.sqrt(np.sum(sig**2, axis=1))  # Magnitude\n",
    "                                else:\n",
    "                                    sig = sig.flatten()\n",
    "                            else:\n",
    "                                sig = sig.flatten()\n",
    "                        \n",
    "                        # Resample signal\n",
    "                        sig_resampled = resample(sig, int(len(sig) * target_fs / orig_fs))\n",
    "                        signals.append(sig_resampled)\n",
    "                    else:\n",
    "                        print(f'Warning: {name} missing for {subject}')\n",
    "                \n",
    "                if len(signals) != len(self.signal_names):\n",
    "                    print(f'Skipping {subject} due to missing modalities')\n",
    "                    continue\n",
    "                \n",
    "                # Ensure all signals have same length\n",
    "                min_len = min(map(len, signals))\n",
    "                signals = [s[:min_len] for s in signals]\n",
    "                signal_matrix = np.stack(signals, axis=1)\n",
    "                \n",
    "                # Resample labels\n",
    "                labels_resampled = resample(labels, min_len)\n",
    "                labels_resampled = np.round(labels_resampled).astype(int)\n",
    "                \n",
    "                # Create sliding windows\n",
    "                win_data, win_labels = self.create_windows(signal_matrix, labels_resampled)\n",
    "                \n",
    "                all_data.extend(win_data)\n",
    "                all_labels.extend(win_labels)\n",
    "                all_subjects.extend([subject]*len(win_data))\n",
    "                \n",
    "                print(f'Loaded {len(win_data)} sliding windows for {subject}')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f'Error processing {subject}: {e}')\n",
    "                continue\n",
    "        \n",
    "        return np.array(all_data), np.array(all_labels), np.array(all_subjects)\n",
    "    \n",
    "    def create_windows(self, data, labels):\n",
    "        step = int(self.window_size * (1 - self.overlap))\n",
    "        windows = []\n",
    "        window_labels = []\n",
    "        \n",
    "        for start in range(0, data.shape[0] - self.window_size + 1, step):\n",
    "            end = start + self.window_size\n",
    "            label_window = labels[start:end]\n",
    "            \n",
    "            # Handle newer scipy versions\n",
    "            mode_result = mode(label_window, keepdims=True)\n",
    "            lbl = int(mode_result[0][0])\n",
    "            \n",
    "            if lbl == 1:  # Baseline\n",
    "                windows.append(data[start:end])\n",
    "                window_labels.append(0)\n",
    "            elif lbl == 2:  # Stress\n",
    "                windows.append(data[start:end])\n",
    "                window_labels.append(1)\n",
    "        \n",
    "        return windows, window_labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f610ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rate = 0.0001\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c60e7697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 440 sliding windows for S2\n",
      "Loaded 445 sliding windows for S3\n",
      "Loaded 449 sliding windows for S4\n",
      "Loaded 460 sliding windows for S5\n",
      "Loaded 458 sliding windows for S6\n",
      "Loaded 457 sliding windows for S7\n",
      "Loaded 460 sliding windows for S8\n",
      "Loaded 456 sliding windows for S9\n",
      "Loaded 476 sliding windows for S10\n",
      "Loaded 465 sliding windows for S11\n",
      "Loaded 461 sliding windows for S13\n",
      "Loaded 464 sliding windows for S14\n",
      "Loaded 464 sliding windows for S15\n",
      "Loaded 463 sliding windows for S16\n",
      "Loaded 476 sliding windows for S17\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = '/Users/kumar/Library/Mobile Documents/com~apple~CloudDocs/Phoenix/OVGU/HiWi2/Tasks/10_WESAD/WESAD.nosync'\n",
    "# DATASET_PATH =  '/home/bumu60du/WESAD_Dataset'\n",
    "\n",
    "ds = WESADDataset(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d1b6a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window size: How many timesteps or consecutive records each sample contains\n",
    "# Batch size: How many independent samples are processed in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc06ac98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6894\n",
      "128\n",
      "6\n",
      "Input sample: tensor([[ 9.5370e-01,  2.2468e+00,  5.5277e+00,  2.9131e+01, -1.4182e-01,\n",
      "         -6.0475e-03],\n",
      "        [ 9.1147e-01,  2.3274e+00,  5.5262e+00,  2.9136e+01, -1.3497e-01,\n",
      "          6.8507e-05],\n",
      "        [ 9.0827e-01,  2.3982e+00,  5.5229e+00,  2.9145e+01, -9.1329e-02,\n",
      "         -3.4008e-03],\n",
      "        [ 9.2792e-01,  2.4003e+00,  5.5208e+00,  2.9142e+01, -1.2794e-01,\n",
      "          5.1459e-05],\n",
      "        [ 9.3718e-01,  2.4020e+00,  5.5201e+00,  2.9131e+01, -1.3628e-01,\n",
      "         -4.2756e-03],\n",
      "        [ 9.3415e-01,  2.3529e+00,  5.5167e+00,  2.9139e+01, -5.8765e-02,\n",
      "         -2.8011e-03],\n",
      "        [ 9.2376e-01,  2.2870e+00,  5.5171e+00,  2.9137e+01,  7.2924e-02,\n",
      "         -3.5566e-03],\n",
      "        [ 9.2641e-01,  2.2015e+00,  5.5147e+00,  2.9140e+01,  6.3188e-02,\n",
      "         -2.0663e-03],\n",
      "        [ 9.3307e-01,  2.0973e+00,  5.5099e+00,  2.9133e+01,  3.0525e-02,\n",
      "         -2.8087e-03],\n",
      "        [ 9.3486e-01,  1.9369e+00,  5.5108e+00,  2.9139e+01,  1.3204e-02,\n",
      "         -2.8071e-03],\n",
      "        [ 9.2933e-01,  1.7631e+00,  5.5000e+00,  2.9140e+01,  2.2823e-02,\n",
      "         -3.1275e-03],\n",
      "        [ 9.2227e-01,  1.5894e+00,  5.5071e+00,  2.9145e+01,  3.0918e-02,\n",
      "         -1.7953e-03],\n",
      "        [ 9.2795e-01,  1.3780e+00,  5.5033e+00,  2.9135e+01,  2.6511e-02,\n",
      "         -3.2200e-03],\n",
      "        [ 9.2741e-01,  1.1336e+00,  5.5047e+00,  2.9129e+01,  2.5400e-02,\n",
      "         -2.0039e-03],\n",
      "        [ 9.3142e-01,  9.2001e-01,  5.5016e+00,  2.9133e+01,  3.2817e-02,\n",
      "         -2.4560e-03],\n",
      "        [ 9.3158e-01,  6.1808e-01,  5.5032e+00,  2.9136e+01,  1.7588e-02,\n",
      "         -3.9785e-03],\n",
      "        [ 9.3823e-01,  4.0053e-01,  5.4983e+00,  2.9140e+01,  1.7769e-02,\n",
      "         -3.5007e-03],\n",
      "        [ 9.3228e-01,  1.5564e-01,  5.4957e+00,  2.9140e+01,  7.9319e-03,\n",
      "         -1.0183e-03],\n",
      "        [ 9.2586e-01, -8.3471e-02,  5.4955e+00,  2.9133e+01,  8.0591e-03,\n",
      "         -3.0642e-03],\n",
      "        [ 9.2685e-01, -3.0139e-01,  5.4920e+00,  2.9133e+01,  2.5126e-02,\n",
      "         -3.8985e-04],\n",
      "        [ 9.2480e-01, -5.3743e-01,  5.4917e+00,  2.9143e+01,  1.0561e-01,\n",
      "         -4.4146e-03],\n",
      "        [ 9.2867e-01, -7.2979e-01,  5.4885e+00,  2.9140e+01,  4.2990e-02,\n",
      "         -1.9708e-03],\n",
      "        [ 9.3386e-01, -9.3147e-01,  5.4838e+00,  2.9136e+01, -6.3633e-02,\n",
      "         -5.3830e-03],\n",
      "        [ 9.3533e-01, -1.1170e+00,  5.4837e+00,  2.9139e+01,  4.0660e-02,\n",
      "          3.6344e-03],\n",
      "        [ 9.3273e-01, -1.2398e+00,  5.4882e+00,  2.9134e+01,  4.2712e-01,\n",
      "         -7.5649e-03],\n",
      "        [ 9.2777e-01, -1.3732e+00,  5.4806e+00,  2.9155e+01, -1.7439e-02,\n",
      "         -5.4820e-03],\n",
      "        [ 9.2553e-01, -1.4722e+00,  5.4771e+00,  2.9141e+01, -2.2645e-01,\n",
      "          2.0953e-03],\n",
      "        [ 9.2930e-01, -1.5382e+00,  5.4739e+00,  2.9139e+01, -1.7245e-01,\n",
      "         -4.9797e-03],\n",
      "        [ 9.2468e-01, -1.5631e+00,  5.4704e+00,  2.9144e+01, -1.7141e-01,\n",
      "         -1.4562e-03],\n",
      "        [ 9.2818e-01, -1.5494e+00,  5.4668e+00,  2.9137e+01, -1.3465e-01,\n",
      "         -4.0458e-03],\n",
      "        [ 9.3386e-01, -1.5544e+00,  5.4642e+00,  2.9145e+01, -1.8441e-01,\n",
      "         -1.0279e-03],\n",
      "        [ 9.3041e-01, -1.4492e+00,  5.4596e+00,  2.9137e+01, -1.7289e-01,\n",
      "         -5.1192e-03],\n",
      "        [ 9.2678e-01, -1.3758e+00,  5.4578e+00,  2.9140e+01, -7.1046e-02,\n",
      "         -2.5904e-03],\n",
      "        [ 9.2393e-01, -1.2194e+00,  5.4565e+00,  2.9144e+01,  5.8989e-02,\n",
      "         -2.8639e-03],\n",
      "        [ 9.2601e-01, -1.0923e+00,  5.4494e+00,  2.9143e+01,  2.6188e-02,\n",
      "         -2.2362e-03],\n",
      "        [ 9.2795e-01, -9.3744e-01,  5.4489e+00,  2.9146e+01,  1.5496e-02,\n",
      "         -2.6375e-03],\n",
      "        [ 9.3092e-01, -7.2469e-01,  5.4429e+00,  2.9140e+01, -9.5544e-03,\n",
      "         -2.9184e-03],\n",
      "        [ 9.2622e-01, -5.1307e-01,  5.4412e+00,  2.9142e+01,  1.9386e-02,\n",
      "         -3.1979e-03],\n",
      "        [ 9.3054e-01, -2.9416e-01,  5.4368e+00,  2.9144e+01,  7.0839e-03,\n",
      "         -9.9177e-04],\n",
      "        [ 9.2858e-01, -4.5899e-02,  5.4337e+00,  2.9142e+01,  1.1753e-02,\n",
      "         -4.2418e-03],\n",
      "        [ 9.2772e-01,  1.9366e-01,  5.4273e+00,  2.9152e+01,  8.2535e-04,\n",
      "         -1.7768e-03],\n",
      "        [ 9.2868e-01,  4.7644e-01,  5.4286e+00,  2.9143e+01,  1.8235e-02,\n",
      "         -4.7033e-03],\n",
      "        [ 9.2773e-01,  7.0185e-01,  5.4251e+00,  2.9151e+01, -9.9973e-03,\n",
      "         -9.7530e-04],\n",
      "        [ 9.3240e-01,  9.6962e-01,  5.4220e+00,  2.9135e+01,  2.5259e-02,\n",
      "         -5.3561e-03],\n",
      "        [ 9.2510e-01,  1.2923e+00,  5.4182e+00,  2.9144e+01, -7.8287e-03,\n",
      "         -1.6298e-03],\n",
      "        [ 9.2612e-01,  1.5588e+00,  5.4167e+00,  2.9139e+01,  9.3687e-02,\n",
      "         -3.1720e-03],\n",
      "        [ 9.3136e-01,  1.8347e+00,  5.4141e+00,  2.9141e+01,  7.7938e-02,\n",
      "         -3.2325e-03],\n",
      "        [ 9.2983e-01,  2.1281e+00,  5.4120e+00,  2.9140e+01, -5.0303e-03,\n",
      "         -4.4098e-03],\n",
      "        [ 9.2858e-01,  2.3760e+00,  5.4101e+00,  2.9139e+01, -6.0930e-02,\n",
      "          1.0848e-03],\n",
      "        [ 9.2613e-01,  2.6102e+00,  5.4078e+00,  2.9138e+01,  2.4560e-01,\n",
      "         -2.7127e-03],\n",
      "        [ 9.3011e-01,  2.8307e+00,  5.4063e+00,  2.9146e+01,  2.4641e-01,\n",
      "         -9.7966e-03],\n",
      "        [ 9.3405e-01,  3.0473e+00,  5.4055e+00,  2.9146e+01, -1.5378e-01,\n",
      "          2.0124e-03],\n",
      "        [ 9.2690e-01,  3.2344e+00,  5.3996e+00,  2.9158e+01, -1.5046e-01,\n",
      "         -4.2620e-03],\n",
      "        [ 9.2556e-01,  3.4168e+00,  5.4004e+00,  2.9145e+01, -1.2950e-01,\n",
      "         -7.8114e-04],\n",
      "        [ 9.2672e-01,  3.5337e+00,  5.3980e+00,  2.9152e+01, -1.0195e-01,\n",
      "         -4.3873e-03],\n",
      "        [ 9.3605e-01,  3.6656e+00,  5.3948e+00,  2.9153e+01, -1.0251e-01,\n",
      "         -2.1183e-03],\n",
      "        [ 9.3625e-01,  3.7671e+00,  5.3980e+00,  2.9148e+01, -1.3085e-01,\n",
      "         -1.3010e-03],\n",
      "        [ 9.2546e-01,  3.8620e+00,  5.3953e+00,  2.9151e+01, -7.7351e-02,\n",
      "         -5.3071e-03],\n",
      "        [ 9.1851e-01,  3.8915e+00,  5.3953e+00,  2.9146e+01,  5.0828e-02,\n",
      "         -1.2735e-03],\n",
      "        [ 9.2913e-01,  3.9232e+00,  5.3927e+00,  2.9147e+01,  8.4372e-02,\n",
      "         -1.7768e-03],\n",
      "        [ 9.3059e-01,  3.9328e+00,  5.3901e+00,  2.9144e+01,  4.8343e-02,\n",
      "         -3.3394e-03],\n",
      "        [ 9.3230e-01,  3.9692e+00,  5.3879e+00,  2.9153e+01,  4.4173e-02,\n",
      "         -2.0874e-03],\n",
      "        [ 9.2814e-01,  3.9305e+00,  5.3870e+00,  2.9149e+01,  2.5079e-02,\n",
      "         -2.1963e-03],\n",
      "        [ 9.2478e-01,  3.9048e+00,  5.3850e+00,  2.9149e+01,  3.3570e-02,\n",
      "         -3.0172e-03],\n",
      "        [ 9.2708e-01,  3.8148e+00,  5.3861e+00,  2.9149e+01,  1.9724e-02,\n",
      "         -1.5263e-03],\n",
      "        [ 9.2846e-01,  3.7635e+00,  5.3826e+00,  2.9158e+01,  2.5118e-02,\n",
      "         -4.0933e-03],\n",
      "        [ 9.2581e-01,  3.6901e+00,  5.3824e+00,  2.9145e+01,  1.4667e-02,\n",
      "         -2.9790e-03],\n",
      "        [ 9.2583e-01,  3.5927e+00,  5.3815e+00,  2.9155e+01,  1.3739e-02,\n",
      "         -2.0536e-03],\n",
      "        [ 9.2423e-01,  3.4719e+00,  5.3811e+00,  2.9150e+01,  2.6259e-02,\n",
      "         -4.3870e-03],\n",
      "        [ 9.3004e-01,  3.4099e+00,  5.3813e+00,  2.9146e+01,  1.3406e-01,\n",
      "         -2.4613e-03],\n",
      "        [ 9.2382e-01,  3.3103e+00,  5.3802e+00,  2.9156e+01,  5.4915e-02,\n",
      "         -2.4785e-03],\n",
      "        [ 9.3032e-01,  3.2277e+00,  5.3743e+00,  2.9158e+01, -3.7475e-02,\n",
      "         -6.8524e-03],\n",
      "        [ 9.3651e-01,  3.1079e+00,  5.3754e+00,  2.9158e+01,  9.9262e-03,\n",
      "          2.9890e-03],\n",
      "        [ 9.1922e-01,  3.0281e+00,  5.3792e+00,  2.9147e+01,  4.0852e-01,\n",
      "         -7.8380e-03],\n",
      "        [ 9.3182e-01,  2.9786e+00,  5.3798e+00,  2.9143e+01,  3.5816e-02,\n",
      "         -7.3622e-03],\n",
      "        [ 9.2993e-01,  2.8615e+00,  5.3737e+00,  2.9152e+01, -1.8606e-01,\n",
      "          2.5580e-03],\n",
      "        [ 9.2439e-01,  2.7904e+00,  5.3723e+00,  2.9154e+01, -1.7015e-01,\n",
      "         -4.3733e-03],\n",
      "        [ 9.3288e-01,  2.7259e+00,  5.3669e+00,  2.9149e+01, -1.4253e-01,\n",
      "          4.8742e-04],\n",
      "        [ 9.3164e-01,  2.6621e+00,  5.3696e+00,  2.9153e+01, -1.0674e-01,\n",
      "         -6.9217e-03],\n",
      "        [ 9.2670e-01,  2.5850e+00,  5.3666e+00,  2.9151e+01, -1.1957e-01,\n",
      "         -8.6126e-04],\n",
      "        [ 9.3476e-01,  2.5166e+00,  5.3656e+00,  2.9147e+01, -1.3886e-01,\n",
      "         -3.2004e-03],\n",
      "        [ 9.3342e-01,  2.4902e+00,  5.3663e+00,  2.9150e+01, -2.9015e-02,\n",
      "         -3.3996e-03],\n",
      "        [ 9.2838e-01,  2.4552e+00,  5.3658e+00,  2.9142e+01,  6.4753e-02,\n",
      "         -1.7521e-03],\n",
      "        [ 9.1982e-01,  2.3929e+00,  5.3605e+00,  2.9144e+01,  7.2989e-02,\n",
      "         -1.1824e-03],\n",
      "        [ 9.2786e-01,  2.3768e+00,  5.3650e+00,  2.9146e+01,  3.8600e-02,\n",
      "         -5.0861e-03],\n",
      "        [ 9.3320e-01,  2.3537e+00,  5.3675e+00,  2.9144e+01,  5.2281e-02,\n",
      "         -8.6707e-04],\n",
      "        [ 9.2748e-01,  2.2809e+00,  5.3710e+00,  2.9148e+01,  3.4575e-02,\n",
      "         -2.8968e-03],\n",
      "        [ 9.3422e-01,  2.2189e+00,  5.3707e+00,  2.9143e+01,  5.4608e-02,\n",
      "         -2.2313e-03],\n",
      "        [ 9.2910e-01,  2.2363e+00,  5.3699e+00,  2.9143e+01,  1.9783e-02,\n",
      "         -4.0577e-03],\n",
      "        [ 9.2634e-01,  2.1763e+00,  5.3693e+00,  2.9146e+01,  4.4835e-02,\n",
      "         -1.1691e-03],\n",
      "        [ 9.2709e-01,  2.1305e+00,  5.3694e+00,  2.9147e+01,  9.5954e-03,\n",
      "         -3.9677e-03],\n",
      "        [ 9.2602e-01,  2.0736e+00,  5.3665e+00,  2.9142e+01,  9.9458e-02,\n",
      "          6.8472e-05],\n",
      "        [ 9.2556e-01,  2.0332e+00,  5.3696e+00,  2.9141e+01,  1.2476e-01,\n",
      "         -3.4665e-03],\n",
      "        [ 9.2637e-01,  1.9848e+00,  5.3667e+00,  2.9146e+01,  5.6699e-02,\n",
      "         -1.7735e-03],\n",
      "        [ 9.2720e-01,  1.9617e+00,  5.3623e+00,  2.9146e+01, -1.1250e-01,\n",
      "         -4.7628e-03],\n",
      "        [ 9.3389e-01,  1.9159e+00,  5.3663e+00,  2.9145e+01,  2.2309e-01,\n",
      "          4.2860e-03],\n",
      "        [ 9.2542e-01,  1.8623e+00,  5.3685e+00,  2.9148e+01,  4.9225e-01,\n",
      "         -1.0138e-02],\n",
      "        [ 9.2918e-01,  1.8300e+00,  5.3651e+00,  2.9151e+01, -1.8433e-01,\n",
      "         -9.9069e-04],\n",
      "        [ 9.3221e-01,  1.7686e+00,  5.3597e+00,  2.9142e+01, -1.9098e-01,\n",
      "         -1.4657e-03],\n",
      "        [ 9.1826e-01,  1.7245e+00,  5.3572e+00,  2.9150e+01, -2.0465e-01,\n",
      "         -1.7910e-03],\n",
      "        [ 9.1946e-01,  1.7372e+00,  5.3566e+00,  2.9146e+01, -1.3523e-01,\n",
      "         -2.2171e-03],\n",
      "        [ 9.3449e-01,  1.6670e+00,  5.3539e+00,  2.9152e+01, -1.4246e-01,\n",
      "         -2.9876e-03],\n",
      "        [ 9.3692e-01,  1.6652e+00,  5.3522e+00,  2.9144e+01, -1.5284e-01,\n",
      "         -2.6084e-03],\n",
      "        [ 9.2737e-01,  1.6272e+00,  5.3512e+00,  2.9145e+01, -1.4004e-01,\n",
      "         -2.3201e-03],\n",
      "        [ 9.2560e-01,  1.5848e+00,  5.3490e+00,  2.9146e+01, -8.6974e-03,\n",
      "         -3.2032e-03],\n",
      "        [ 9.2972e-01,  1.5354e+00,  5.3516e+00,  2.9140e+01,  4.0476e-02,\n",
      "         -2.5758e-03],\n",
      "        [ 9.2297e-01,  1.5250e+00,  5.3462e+00,  2.9144e+01,  1.3877e-02,\n",
      "         -1.7152e-03],\n",
      "        [ 9.3024e-01,  1.4874e+00,  5.3442e+00,  2.9151e+01,  1.9308e-02,\n",
      "         -1.8711e-03],\n",
      "        [ 9.3900e-01,  1.4706e+00,  5.3431e+00,  2.9147e+01, -3.2389e-03,\n",
      "         -2.7212e-03],\n",
      "        [ 9.2893e-01,  1.3996e+00,  5.3401e+00,  2.9147e+01,  1.5001e-02,\n",
      "         -3.3622e-03],\n",
      "        [ 9.2685e-01,  1.3364e+00,  5.3400e+00,  2.9145e+01,  5.8320e-03,\n",
      "         -2.7422e-03],\n",
      "        [ 9.2674e-01,  1.3260e+00,  5.3387e+00,  2.9144e+01,  2.3325e-02,\n",
      "         -2.2890e-03],\n",
      "        [ 9.2469e-01,  1.2833e+00,  5.3344e+00,  2.9146e+01, -2.2799e-02,\n",
      "         -2.6675e-03],\n",
      "        [ 9.2793e-01,  1.2411e+00,  5.3324e+00,  2.9139e+01,  1.0300e-01,\n",
      "         -3.2363e-03],\n",
      "        [ 9.2798e-01,  1.1937e+00,  5.3325e+00,  2.9150e+01,  9.9305e-02,\n",
      "         -5.8328e-03],\n",
      "        [ 9.3000e-01,  1.1303e+00,  5.3267e+00,  2.9157e+01, -4.0260e-03,\n",
      "         -1.1226e-04],\n",
      "        [ 9.2951e-01,  1.0696e+00,  5.3273e+00,  2.9146e+01, -1.3085e-01,\n",
      "         -6.6852e-04],\n",
      "        [ 9.2652e-01,  1.0139e+00,  5.3260e+00,  2.9149e+01,  3.5436e-01,\n",
      "         -2.8464e-05],\n",
      "        [ 9.3053e-01,  9.4570e-01,  5.3280e+00,  2.9149e+01,  2.8699e-01,\n",
      "         -1.0285e-02],\n",
      "        [ 9.2807e-01,  8.8047e-01,  5.3264e+00,  2.9150e+01, -2.6713e-01,\n",
      "         -1.8465e-04],\n",
      "        [ 9.3335e-01,  8.4490e-01,  5.3210e+00,  2.9141e+01, -1.7231e-01,\n",
      "         -2.5964e-03],\n",
      "        [ 9.2799e-01,  7.4593e-01,  5.3205e+00,  2.9150e+01, -2.0877e-01,\n",
      "         -3.3760e-03],\n",
      "        [ 9.2161e-01,  7.0666e-01,  5.3206e+00,  2.9152e+01, -1.1553e-01,\n",
      "         -3.7251e-03],\n",
      "        [ 9.3624e-01,  6.9003e-01,  5.3176e+00,  2.9146e+01, -1.6939e-01,\n",
      "         -9.1883e-04],\n",
      "        [ 9.3351e-01,  5.7882e-01,  5.3165e+00,  2.9155e+01, -1.4562e-01,\n",
      "         -2.8399e-03],\n",
      "        [ 9.2846e-01,  5.4453e-01,  5.3183e+00,  2.9154e+01, -1.4330e-01,\n",
      "         -3.8479e-03],\n",
      "        [ 9.2482e-01,  4.7605e-01,  5.3164e+00,  2.9145e+01,  2.7542e-02,\n",
      "         -3.6684e-03],\n",
      "        [ 9.2480e-01,  4.4571e-01,  5.3136e+00,  2.9156e+01,  2.9194e-02,\n",
      "         -1.5195e-03]])\n",
      "Label sample: tensor(0)\n"
     ]
    }
   ],
   "source": [
    "print(len(ds)) # How 6894?, all devices sampled at same rate?\n",
    "input_sample, label_sample = ds[0]\n",
    "print(len(input_sample)) # Time steps = 128, (window size is downsampled from 700 Hz to 32Hz, 128/32 = 4 seconds of data per window)\n",
    "print(len(input_sample[0])) # ['ACC','Resp','EDA','Temp','ECG','EMG'], 6 sensors\n",
    "print('Input sample:', input_sample) # 128 * 6\n",
    "print('Label sample:', label_sample) # 0 for Baseline, 1 for Stress label for 4 seconds window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6da3933b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 9.53695909e-01  2.24679160e+00  5.52765841e+00  2.91313362e+01\n",
      "   -1.41824139e-01 -6.04750620e-03]\n",
      "  [ 9.11465368e-01  2.32740996e+00  5.52615135e+00  2.91355190e+01\n",
      "   -1.34965516e-01  6.85065422e-05]\n",
      "  [ 9.08267120e-01  2.39820206e+00  5.52290337e+00  2.91450386e+01\n",
      "   -9.13289276e-02 -3.40082603e-03]\n",
      "  ...\n",
      "  [ 9.28455273e-01  5.44533803e-01  5.31834160e+00  2.91541538e+01\n",
      "   -1.43304494e-01 -3.84787691e-03]\n",
      "  [ 9.24815791e-01  4.76052949e-01  5.31637878e+00  2.91448460e+01\n",
      "    2.75417114e-02 -3.66836806e-03]\n",
      "  [ 9.24795830e-01  4.45706483e-01  5.31359401e+00  2.91560955e+01\n",
      "    2.91937129e-02 -1.51953093e-03]]\n",
      "\n",
      " [[ 9.19668626e-01  3.95555448e-01  5.31144317e+00  2.91575813e+01\n",
      "    3.24984189e-02 -3.88746767e-03]\n",
      "  [ 9.35759078e-01  3.17082208e-01  5.30857120e+00  2.91454124e+01\n",
      "   -1.36019995e-04 -2.01393702e-03]\n",
      "  [ 9.38470096e-01  2.59713959e-01  5.30977232e+00  2.91462269e+01\n",
      "    1.47452032e-02 -4.34544230e-03]\n",
      "  ...\n",
      "  [ 9.28935423e-01 -8.98991761e-01  5.18789230e+00  2.91644592e+01\n",
      "    2.88510673e-02 -2.66250985e-03]\n",
      "  [ 9.25370948e-01 -9.05587944e-01  5.18804404e+00  2.91660652e+01\n",
      "    1.12392297e-02 -2.71640040e-03]\n",
      "  [ 9.30849452e-01 -9.46053396e-01  5.18893590e+00  2.91662636e+01\n",
      "    1.08358100e-02 -2.53560087e-03]]\n",
      "\n",
      " [[ 9.34073567e-01 -9.57054190e-01  5.18850463e+00  2.91703453e+01\n",
      "    9.17277627e-03 -2.18515582e-03]\n",
      "  [ 9.27274603e-01 -1.02416435e+00  5.18989735e+00  2.91719131e+01\n",
      "    1.84047150e-02 -2.03553101e-03]\n",
      "  [ 9.28775041e-01 -1.06793122e+00  5.18836841e+00  2.91659737e+01\n",
      "    4.28970055e-03 -3.44937939e-03]\n",
      "  ...\n",
      "  [ 9.39657480e-01  8.26361832e-01  5.14777612e+00  2.91966686e+01\n",
      "   -2.06348232e-01 -3.03840249e-03]\n",
      "  [ 9.45003770e-01  5.51844653e-01  5.14663515e+00  2.92010384e+01\n",
      "   -2.20300137e-01 -2.57672566e-03]\n",
      "  [ 9.38844206e-01  2.94957656e-01  5.14597727e+00  2.92001610e+01\n",
      "   -1.97785919e-01  1.09474232e-04]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 9.49794267e-01  1.55820651e-01  7.33844294e+00  3.45536537e+01\n",
      "    8.90117153e-03 -3.43977121e-03]\n",
      "  [ 9.41361306e-01 -1.21965941e-02  7.33675146e+00  3.45584984e+01\n",
      "    1.68658305e-01 -3.79058872e-03]\n",
      "  [ 9.30867467e-01 -2.42627672e-01  7.33610247e+00  3.45595665e+01\n",
      "    1.58583980e-01 -3.43963042e-03]\n",
      "  ...\n",
      "  [ 9.44492452e-01  2.06170474e+00  7.35273176e+00  3.45654640e+01\n",
      "   -2.55629670e-01 -4.51861025e-03]\n",
      "  [ 9.32750952e-01  1.85359696e+00  7.34937828e+00  3.45686035e+01\n",
      "   -2.12464718e-02 -6.73551461e-03]\n",
      "  [ 9.43432544e-01  1.70584788e+00  7.34789908e+00  3.45607109e+01\n",
      "    1.31385994e-02 -3.70414364e-03]]\n",
      "\n",
      " [[ 9.58368204e-01  1.54160915e+00  7.34790502e+00  3.45618095e+01\n",
      "    1.78207222e-01 -4.44124155e-03]\n",
      "  [ 9.45195068e-01  1.43126725e+00  7.34963629e+00  3.45596275e+01\n",
      "    1.32952572e-01 -4.05367735e-03]\n",
      "  [ 9.34219407e-01  1.22609721e+00  7.34791106e+00  3.45661430e+01\n",
      "    3.74026751e-01 -4.76397183e-03]\n",
      "  ...\n",
      "  [ 9.37985552e-01 -1.56429830e-01  7.34639772e+00  3.45764236e+01\n",
      "    1.94846122e-02 -5.22854818e-03]\n",
      "  [ 9.36331831e-01 -1.47340385e-01  7.35014580e+00  3.45706329e+01\n",
      "   -1.80983495e-02 -5.82428349e-03]\n",
      "  [ 9.40682119e-01 -1.81497466e-01  7.34838821e+00  3.45719070e+01\n",
      "   -2.70541661e-01 -1.74122237e-03]]\n",
      "\n",
      " [[ 9.40347317e-01 -2.13794256e-01  7.34490557e+00  3.45762024e+01\n",
      "    9.83095334e-01 -6.07490286e-03]\n",
      "  [ 9.50146166e-01 -2.75149412e-01  7.36139267e+00  3.45725174e+01\n",
      "    1.80752525e-01 -5.51982235e-03]\n",
      "  [ 9.37099742e-01 -3.75627764e-01  7.35942950e+00  3.45724258e+01\n",
      "   -6.31434445e-01 -1.21334726e-03]\n",
      "  ...\n",
      "  [ 9.54369987e-01 -1.34406933e+00  7.38346737e+00  3.45824547e+01\n",
      "    4.29027567e-01 -7.43302019e-03]\n",
      "  [ 9.54265892e-01 -1.35585642e+00  7.38803565e+00  3.45742760e+01\n",
      "   -6.42327952e-01 -9.32778394e-04]\n",
      "  [ 9.33545145e-01 -1.27790927e+00  7.38297192e+00  3.45874023e+01\n",
      "   -2.01850938e-01 -5.19153985e-03]]]\n",
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(ds.data)\n",
    "print(ds.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b34bb15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise data\n",
    "\n",
    "means = ds.data.mean(axis=(0, 1))   # shape: across batch and time steps\n",
    "stds = ds.data.std(axis=(0, 1))\n",
    "\n",
    "# apply normalization in-place\n",
    "ds.data = (ds.data - means[None, None, :]) / stds[None, None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8400f0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 6894, Train: 4825, Validation: 1034, Test: 1035\n"
     ]
    }
   ],
   "source": [
    "# 2. Train test size\n",
    "\n",
    "train_ratio, val_ratio, test_ratio = 0.7, 0.15, 0.15\n",
    "\n",
    "n_total = len(ds)\n",
    "n_train = int(train_ratio * n_total)  \n",
    "n_val = int(val_ratio * n_total)      \n",
    "n_test = n_total - n_train - n_val    \n",
    "\n",
    "print(f\"Total samples: {n_total}, Train: {n_train}, Validation: {n_val}, Test: {n_test}\")\n",
    "\n",
    "# Train test split\n",
    "train_ds = Subset(ds, range(0, n_train))\n",
    "val_ds   = Subset(ds, range(n_train, n_train + n_val))\n",
    "test_ds  = Subset(ds, range(n_train + n_val, n_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbe6b8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_inputs: tensor([[[ 7.5376e-01,  5.9662e-01,  2.5280e-01, -3.0084e+00, -6.0045e-01,\n",
      "          -7.8230e-01],\n",
      "         [-6.5244e-01,  6.1856e-01,  2.5237e-01, -3.0057e+00, -5.7163e-01,\n",
      "           7.4942e-01],\n",
      "         [-7.5893e-01,  6.3782e-01,  2.5145e-01, -2.9994e+00, -3.8830e-01,\n",
      "          -1.1945e-01],\n",
      "         ...,\n",
      "         [-8.6707e-02,  1.3346e-01,  1.9340e-01, -2.9934e+00, -6.0667e-01,\n",
      "          -2.3141e-01],\n",
      "         [-2.0789e-01,  1.1483e-01,  1.9284e-01, -2.9996e+00,  1.1113e-01,\n",
      "          -1.8646e-01],\n",
      "         [-2.0856e-01,  1.0657e-01,  1.9205e-01, -2.9922e+00,  1.1807e-01,\n",
      "           3.5171e-01]],\n",
      "\n",
      "        [[-3.7929e-01,  9.2928e-02,  1.9144e-01, -2.9912e+00,  1.3195e-01,\n",
      "          -2.4133e-01],\n",
      "         [ 1.5650e-01,  7.1576e-02,  1.9063e-01, -2.9992e+00, -5.1575e-03,\n",
      "           2.2788e-01],\n",
      "         [ 2.4677e-01,  5.5967e-02,  1.9097e-01, -2.9987e+00,  5.7365e-02,\n",
      "          -3.5603e-01],\n",
      "         ...,\n",
      "         [-7.0719e-02, -2.5930e-01,  1.5638e-01, -2.9867e+00,  1.1663e-01,\n",
      "           6.5453e-02],\n",
      "         [-1.8941e-01, -2.6109e-01,  1.5643e-01, -2.9856e+00,  4.2635e-02,\n",
      "           5.1957e-02],\n",
      "         [-6.9854e-03, -2.7210e-01,  1.5668e-01, -2.9855e+00,  4.0940e-02,\n",
      "           9.7237e-02]],\n",
      "\n",
      "        [[ 1.0037e-01, -2.7510e-01,  1.5656e-01, -2.9828e+00,  3.3953e-02,\n",
      "           1.8500e-01],\n",
      "         [-1.2602e-01, -2.9336e-01,  1.5695e-01, -2.9818e+00,  7.2740e-02,\n",
      "           2.2248e-01],\n",
      "         [-7.6059e-02, -3.0527e-01,  1.5652e-01, -2.9857e+00,  1.3437e-02,\n",
      "          -1.3161e-01],\n",
      "         ...,\n",
      "         [ 2.8630e-01,  2.1014e-01,  1.4500e-01, -2.9655e+00, -8.7154e-01,\n",
      "          -2.8687e-02],\n",
      "         [ 4.6433e-01,  1.3545e-01,  1.4468e-01, -2.9626e+00, -9.3016e-01,\n",
      "           8.6938e-02],\n",
      "         [ 2.5922e-01,  6.5557e-02,  1.4449e-01, -2.9632e+00, -8.3557e-01,\n",
      "           7.5968e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.9155e-01, -6.5357e-01, -2.4155e-01, -3.2484e+00,  1.6035e-01,\n",
      "           4.7248e-01],\n",
      "         [ 7.3212e-01, -6.7459e-01, -2.4127e-01, -3.2421e+00, -5.5299e-02,\n",
      "          -1.6537e-01],\n",
      "         [ 8.2366e-01, -6.9978e-01, -2.4071e-01, -3.2422e+00,  2.8905e-01,\n",
      "          -2.8145e-01],\n",
      "         ...,\n",
      "         [ 6.5172e-01,  3.2788e-01, -2.5038e-01, -3.2436e+00,  2.9600e-01,\n",
      "          -2.2374e-01],\n",
      "         [ 6.5297e-01,  2.7933e-01, -2.4969e-01, -3.2414e+00,  2.1784e-01,\n",
      "           5.2570e-01],\n",
      "         [ 8.1599e-01,  2.4257e-01, -2.4942e-01, -3.2408e+00,  1.9143e-01,\n",
      "          -2.3309e-01]],\n",
      "\n",
      "        [[ 7.2992e-01,  1.9432e-01, -2.4990e-01, -3.2443e+00,  6.4662e-02,\n",
      "          -1.8872e-01],\n",
      "         [ 7.7178e-01,  1.4102e-01, -2.4921e-01, -3.2482e+00,  9.5598e-02,\n",
      "          -1.8095e-02],\n",
      "         [ 7.4759e-01,  8.9490e-02, -2.4936e-01, -3.2397e+00, -4.7875e-03,\n",
      "           2.1274e-01],\n",
      "         ...,\n",
      "         [ 7.7320e-01, -1.2139e-01, -2.5830e-01, -3.2359e+00,  1.4268e-01,\n",
      "           1.5521e-01],\n",
      "         [ 6.8309e-01, -9.6596e-02, -2.5802e-01, -3.2358e+00,  1.4096e-01,\n",
      "          -1.0340e-02],\n",
      "         [ 6.2954e-01, -3.5514e-02, -2.5930e-01, -3.2427e+00,  1.1338e-01,\n",
      "           4.4366e-01]],\n",
      "\n",
      "        [[ 6.8626e-01, -4.9305e-04, -2.5917e-01, -3.2398e+00,  1.4471e-01,\n",
      "          -9.1885e-02],\n",
      "         [ 6.9765e-01,  3.6075e-02, -2.5982e-01, -3.2387e+00,  1.0389e-01,\n",
      "           1.5127e-01],\n",
      "         [ 6.6070e-01,  5.9634e-02, -2.5981e-01, -3.2367e+00,  1.1039e-01,\n",
      "          -2.7208e-01],\n",
      "         ...,\n",
      "         [ 6.5386e-01, -1.1283e-02, -2.7069e-01, -3.2263e+00, -3.6273e-01,\n",
      "           1.6497e+00],\n",
      "         [ 8.3627e-01, -6.1303e-02, -2.6904e-01, -3.2252e+00,  1.9031e+00,\n",
      "          -5.0312e-02],\n",
      "         [ 5.8422e-01, -1.0166e-01, -2.6940e-01, -3.2303e+00,  1.1089e+00,\n",
      "          -1.9721e+00]]])\n",
      "batch_labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "32\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# Data Loaders\n",
    "train_dataloader = DataLoader(train_ds, batch_size = 32, shuffle = False) # batch size = grouping 32 samples\n",
    "val_dataloader = DataLoader(val_ds, batch_size = 32, shuffle = False)\n",
    "test_dataloader = DataLoader(test_ds, batch_size = 32, shuffle = False)\n",
    "\n",
    "# Sample batch\n",
    "for batch_inputs, batch_labels in train_dataloader:\n",
    "    print('batch_inputs:', batch_inputs)\n",
    "    print('batch_labels:', batch_labels)\n",
    "    print(len(batch_inputs))\n",
    "    print(len(batch_inputs[0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce06bd2",
   "metadata": {},
   "source": [
    "3. Transformer/ Neural network\n",
    "    1) Create a model\n",
    "    2) Choose a loss function\n",
    "    3) Define a dataset\n",
    "    4) Set an optimizer \n",
    "    5) Run a training loop\n",
    "        Calculate loss (Forward pass)\n",
    "        Compute gradients (Backpropagation)\n",
    "        Updating model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ac404f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_heads = width of attention (how many perspectives are considered in parallel).\n",
    "# num_layers = depth of reasoning (how many times the model refines its understanding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "854743c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabTransformer(\n",
      "  (embedding): Linear(in_features=6, out_features=64, bias=True)\n",
      "  (transformer): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-3): 4 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=64, out_features=256, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=256, out_features=64, bias=True)\n",
      "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# 3.1 TabTransformer model class, modified from Medium\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class TabTransformer(nn.Module):\n",
    "    def __init__(self, num_features, num_classes, dim_embedding, num_heads, num_layers):\n",
    "        super(TabTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(num_features, dim_embedding) # project input features -> embedding\n",
    "        # transformer encoder (batch_first=True so input shape is [batch_size, timesteps, num_features/dim_embedding])\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=dim_embedding,nhead=num_heads,dim_feedforward=dim_embedding * 4,batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.classifier = nn.Linear(dim_embedding, num_classes) # simple linear classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch, timesteps, features]\n",
    "        x = self.embedding(x)            # -> [batch, timesteps, dim_embedding], project input to embedding\n",
    "        x = self.transformer(x)          # -> [batch, timesteps, dim_embedding], passes through multiple [Attention + FFN + Norm] layers\n",
    "        x = torch.mean(x, dim=1)         # -> [batch, dim_embedding], global mean pooling over timesteps \n",
    "        x = self.classifier(x)           # -> [batch, num_classes], final classification head\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = TabTransformer(\n",
    "    num_features = 6,        # 6 sensor features\n",
    "    num_classes = 2,         # Binary classification\n",
    "    dim_embedding = 64,      # Embedding dimension\n",
    "    num_heads = 4,           # Number of attention heads\n",
    "    num_layers = 4,          # Number of transformer layers\n",
    ").to(device)\n",
    "\n",
    "print(model)\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33098ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function criterion and optimizer \n",
    "criterion = nn.CrossEntropyLoss().to(device) # measures the error between predicted and true\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr_rate) # updates the model weights by minimizing the loss\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbb7b872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional libraries\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4716a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#save_dir = \"/home/bumu60du/test\"\n",
    "save_dir = \"/Users/kumar/transformer_timeseries/checkpoints\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "save_path = os.path.join(save_dir, \"best_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "107d4d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] - Loss: 0.6865 and Accuracy: 54.20%\n",
      "Epoch [2/100] - Loss: 0.6180 and Accuracy: 61.87%\n",
      "Epoch [3/100] - Loss: 0.5967 and Accuracy: 65.10%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()        \u001b[38;5;66;03m# Reset gradients\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(x)           \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y) \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[1;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()              \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[14], line 17\u001b[0m, in \u001b[0;36mTabTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# x: [batch, timesteps, features]\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)            \u001b[38;5;66;03m# -> [batch, timesteps, dim_embedding], project input to embedding\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(x)          \u001b[38;5;66;03m# -> [batch, timesteps, dim_embedding], passes through multiple [Attention + FFN + Norm] layers\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(x, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)         \u001b[38;5;66;03m# -> [batch, dim_embedding], global mean pooling over timesteps \u001b[39;00m\n\u001b[1;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(x)           \u001b[38;5;66;03m# -> [batch, num_classes], final classification head\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:524\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    521\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 524\u001b[0m     output \u001b[38;5;241m=\u001b[39m mod(\n\u001b[1;32m    525\u001b[0m         output,\n\u001b[1;32m    526\u001b[0m         src_mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[1;32m    527\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[1;32m    528\u001b[0m         src_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_key_padding_mask_for_layers,\n\u001b[1;32m    529\u001b[0m     )\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    532\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.0\u001b[39m, src\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:935\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    931\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(\n\u001b[1;32m    934\u001b[0m         x\n\u001b[0;32m--> 935\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, src_mask, src_key_padding_mask, is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m    936\u001b[0m     )\n\u001b[1;32m    937\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:949\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\n\u001b[1;32m    943\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    944\u001b[0m     x: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    947\u001b[0m     is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    948\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 949\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    950\u001b[0m         x,\n\u001b[1;32m    951\u001b[0m         x,\n\u001b[1;32m    952\u001b[0m         x,\n\u001b[1;32m    953\u001b[0m         attn_mask\u001b[38;5;241m=\u001b[39mattn_mask,\n\u001b[1;32m    954\u001b[0m         key_padding_mask\u001b[38;5;241m=\u001b[39mkey_padding_mask,\n\u001b[1;32m    955\u001b[0m         need_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    956\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[1;32m    957\u001b[0m     )[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/activation.py:1488\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1462\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1463\u001b[0m         query,\n\u001b[1;32m   1464\u001b[0m         key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1485\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[1;32m   1486\u001b[0m     )\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1488\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1489\u001b[0m         query,\n\u001b[1;32m   1490\u001b[0m         key,\n\u001b[1;32m   1491\u001b[0m         value,\n\u001b[1;32m   1492\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim,\n\u001b[1;32m   1493\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1494\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight,\n\u001b[1;32m   1495\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[1;32m   1496\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_k,\n\u001b[1;32m   1497\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_v,\n\u001b[1;32m   1498\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_zero_attn,\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout,\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_proj\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m   1501\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_proj\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m   1502\u001b[0m         training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining,\n\u001b[1;32m   1503\u001b[0m         key_padding_mask\u001b[38;5;241m=\u001b[39mkey_padding_mask,\n\u001b[1;32m   1504\u001b[0m         need_weights\u001b[38;5;241m=\u001b[39mneed_weights,\n\u001b[1;32m   1505\u001b[0m         attn_mask\u001b[38;5;241m=\u001b[39mattn_mask,\n\u001b[1;32m   1506\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1507\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[1;32m   1508\u001b[0m     )\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/functional.py:6487\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   6484\u001b[0m k \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[1;32m   6485\u001b[0m v \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[0;32m-> 6487\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m scaled_dot_product_attention(\n\u001b[1;32m   6488\u001b[0m     q, k, v, attn_mask, dropout_p, is_causal\n\u001b[1;32m   6489\u001b[0m )\n\u001b[1;32m   6490\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   6491\u001b[0m     attn_output\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(bsz \u001b[38;5;241m*\u001b[39m tgt_len, embed_dim)\n\u001b[1;32m   6492\u001b[0m )\n\u001b[1;32m   6494\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    # Training phase \n",
    "    model.train()                   # model set to training model\n",
    "    epoch_loss = 0.0                # accumulates loss for the epoch\n",
    "    correct = 0                     # to comupte accuracy\n",
    "    total = 0 \n",
    "\n",
    "    for x, y in train_dataloader: # iterate training data in batches\n",
    "        # Move to device\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()        # Reset gradients\n",
    "        outputs = model(x)           # Forward pass\n",
    "        loss = criterion(outputs, y) # Compute loss\n",
    "        loss.backward()              # Backward pass\n",
    "        optimizer.step()             # Update weights\n",
    "\n",
    "        epoch_loss += loss.item() * x.size(0) # loss * batch_size, epoch loss += batchloss\n",
    "        # ---- Compute training accuracy ----\n",
    "        # For classification (outputs: logits)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        correct += (predicted == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    # Epoch summary\n",
    "    epoch_train_loss = epoch_loss / total # avg epoch loss\n",
    "    epoch_train_acc = 100.0 * correct / total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{n_epochs}] - Loss: {epoch_train_loss:.4f} and Accuracy: {epoch_train_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b53fb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 93.33%\n"
     ]
    }
   ],
   "source": [
    "# ---- Evaluation ----\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Convert test data to tensors and move to device\n",
    "with torch.no_grad():\n",
    "    for x, y in test_dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        outputs = model(x)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "        \n",
    "        # Store predictions and labels for additional metrics\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(y.cpu().numpy())\n",
    "    \n",
    "accuracy = 100 * correct / total\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy :.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71d8eaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100]\n",
      "Train - Loss: 0.5609 | Acc: 65.20%\n",
      "Valid - Loss: 0.5132 | Acc: 65.67%\n",
      "--------------------------------------------------\n",
      "Epoch [2/100]\n",
      "Train - Loss: 0.5458 | Acc: 69.10%\n",
      "Valid - Loss: 0.4885 | Acc: 70.70%\n",
      "--------------------------------------------------\n",
      "Epoch [3/100]\n",
      "Train - Loss: 0.5478 | Acc: 67.65%\n",
      "Valid - Loss: 0.4688 | Acc: 74.95%\n",
      "--------------------------------------------------\n",
      "Epoch [4/100]\n",
      "Train - Loss: 0.5046 | Acc: 70.90%\n",
      "Valid - Loss: 0.4141 | Acc: 81.24%\n",
      "--------------------------------------------------\n",
      "Epoch [5/100]\n",
      "Train - Loss: 0.4756 | Acc: 75.19%\n",
      "Valid - Loss: 0.3428 | Acc: 84.62%\n",
      "--------------------------------------------------\n",
      "Epoch [6/100]\n",
      "Train - Loss: 0.4196 | Acc: 79.96%\n",
      "Valid - Loss: 0.3255 | Acc: 85.59%\n",
      "--------------------------------------------------\n",
      "Epoch [7/100]\n",
      "Train - Loss: 0.3852 | Acc: 81.72%\n",
      "Valid - Loss: 0.3271 | Acc: 85.20%\n",
      "--------------------------------------------------\n",
      "Epoch [8/100]\n",
      "Train - Loss: 0.3627 | Acc: 84.79%\n",
      "Valid - Loss: 0.3119 | Acc: 85.69%\n",
      "--------------------------------------------------\n",
      "Epoch [9/100]\n",
      "Train - Loss: 0.3460 | Acc: 85.06%\n",
      "Valid - Loss: 0.3080 | Acc: 85.78%\n",
      "--------------------------------------------------\n",
      "Epoch [10/100]\n",
      "Train - Loss: 0.3125 | Acc: 86.98%\n",
      "Valid - Loss: 0.2998 | Acc: 86.75%\n",
      "--------------------------------------------------\n",
      "Epoch [11/100]\n",
      "Train - Loss: 0.2999 | Acc: 87.40%\n",
      "Valid - Loss: 0.2946 | Acc: 86.75%\n",
      "--------------------------------------------------\n",
      "Epoch [12/100]\n",
      "Train - Loss: 0.2804 | Acc: 88.56%\n",
      "Valid - Loss: 0.2892 | Acc: 88.01%\n",
      "--------------------------------------------------\n",
      "Epoch [13/100]\n",
      "Train - Loss: 0.2701 | Acc: 89.06%\n",
      "Valid - Loss: 0.2846 | Acc: 88.10%\n",
      "--------------------------------------------------\n",
      "Epoch [14/100]\n",
      "Train - Loss: 0.2614 | Acc: 89.53%\n",
      "Valid - Loss: 0.2751 | Acc: 88.30%\n",
      "--------------------------------------------------\n",
      "Epoch [15/100]\n",
      "Train - Loss: 0.2489 | Acc: 90.05%\n",
      "Valid - Loss: 0.2811 | Acc: 88.97%\n",
      "--------------------------------------------------\n",
      "Epoch [16/100]\n",
      "Train - Loss: 0.2415 | Acc: 90.07%\n",
      "Valid - Loss: 0.2717 | Acc: 90.04%\n",
      "--------------------------------------------------\n",
      "Epoch [17/100]\n",
      "Train - Loss: 0.2208 | Acc: 91.23%\n",
      "Valid - Loss: 0.2642 | Acc: 90.52%\n",
      "--------------------------------------------------\n",
      "Epoch [18/100]\n",
      "Train - Loss: 0.2085 | Acc: 91.79%\n",
      "Valid - Loss: 0.2577 | Acc: 91.20%\n",
      "--------------------------------------------------\n",
      "Epoch [19/100]\n",
      "Train - Loss: 0.1990 | Acc: 92.25%\n",
      "Valid - Loss: 0.2448 | Acc: 91.78%\n",
      "--------------------------------------------------\n",
      "Epoch [20/100]\n",
      "Train - Loss: 0.1982 | Acc: 91.81%\n",
      "Valid - Loss: 0.1905 | Acc: 91.49%\n",
      "--------------------------------------------------\n",
      "Epoch [21/100]\n",
      "Train - Loss: 0.1890 | Acc: 92.25%\n",
      "Valid - Loss: 0.2371 | Acc: 91.68%\n",
      "--------------------------------------------------\n",
      "Epoch [22/100]\n",
      "Train - Loss: 0.1771 | Acc: 92.56%\n",
      "Valid - Loss: 0.2418 | Acc: 91.59%\n",
      "--------------------------------------------------\n",
      "Epoch [23/100]\n",
      "Train - Loss: 0.2751 | Acc: 89.20%\n",
      "Valid - Loss: 0.9573 | Acc: 62.28%\n",
      "--------------------------------------------------\n",
      "Epoch [24/100]\n",
      "Train - Loss: 0.3136 | Acc: 87.15%\n",
      "Valid - Loss: 0.2508 | Acc: 88.88%\n",
      "--------------------------------------------------\n",
      "Epoch [25/100]\n",
      "Train - Loss: 0.1662 | Acc: 93.22%\n",
      "Valid - Loss: 0.2169 | Acc: 91.01%\n",
      "--------------------------------------------------\n",
      "Epoch [26/100]\n",
      "Train - Loss: 0.1737 | Acc: 92.83%\n",
      "Valid - Loss: 0.2189 | Acc: 90.62%\n",
      "--------------------------------------------------\n",
      "Epoch [27/100]\n",
      "Train - Loss: 0.1460 | Acc: 93.76%\n",
      "Valid - Loss: 0.2043 | Acc: 91.68%\n",
      "--------------------------------------------------\n",
      "Epoch [28/100]\n",
      "Train - Loss: 0.1458 | Acc: 93.66%\n",
      "Valid - Loss: 0.2128 | Acc: 92.17%\n",
      "--------------------------------------------------\n",
      "Epoch [29/100]\n",
      "Train - Loss: 0.1338 | Acc: 94.32%\n",
      "Valid - Loss: 0.1973 | Acc: 92.84%\n",
      "--------------------------------------------------\n",
      "Epoch [30/100]\n",
      "Train - Loss: 0.1304 | Acc: 94.40%\n",
      "Valid - Loss: 0.2151 | Acc: 92.55%\n",
      "--------------------------------------------------\n",
      "Epoch [31/100]\n",
      "Train - Loss: 0.1169 | Acc: 95.03%\n",
      "Valid - Loss: 0.2086 | Acc: 92.84%\n",
      "--------------------------------------------------\n",
      "Epoch [32/100]\n",
      "Train - Loss: 0.1120 | Acc: 95.44%\n",
      "Valid - Loss: 0.2308 | Acc: 92.36%\n",
      "--------------------------------------------------\n",
      "Epoch [33/100]\n",
      "Train - Loss: 0.1028 | Acc: 95.85%\n",
      "Valid - Loss: 0.2359 | Acc: 92.36%\n",
      "--------------------------------------------------\n",
      "Epoch [34/100]\n",
      "Train - Loss: 0.0981 | Acc: 96.17%\n",
      "Valid - Loss: 0.2762 | Acc: 91.20%\n",
      "--------------------------------------------------\n",
      "Epoch [35/100]\n",
      "Train - Loss: 0.0854 | Acc: 96.70%\n",
      "Valid - Loss: 0.2926 | Acc: 90.72%\n",
      "--------------------------------------------------\n",
      "Epoch [36/100]\n",
      "Train - Loss: 0.0809 | Acc: 96.83%\n",
      "Valid - Loss: 0.3357 | Acc: 89.85%\n",
      "--------------------------------------------------\n",
      "Epoch [37/100]\n",
      "Train - Loss: 0.0686 | Acc: 97.43%\n",
      "Valid - Loss: 0.3871 | Acc: 88.68%\n",
      "--------------------------------------------------\n",
      "Epoch [38/100]\n",
      "Train - Loss: 0.0641 | Acc: 97.74%\n",
      "Valid - Loss: 0.4370 | Acc: 87.04%\n",
      "--------------------------------------------------\n",
      "Epoch [39/100]\n",
      "Train - Loss: 0.0564 | Acc: 98.07%\n",
      "Valid - Loss: 0.4895 | Acc: 85.30%\n",
      "--------------------------------------------------\n",
      "Epoch [40/100]\n",
      "Train - Loss: 0.0556 | Acc: 97.89%\n",
      "Valid - Loss: 0.5658 | Acc: 83.56%\n",
      "--------------------------------------------------\n",
      "Epoch [41/100]\n",
      "Train - Loss: 0.0513 | Acc: 98.11%\n",
      "Valid - Loss: 0.7191 | Acc: 80.27%\n",
      "--------------------------------------------------\n",
      "Epoch [42/100]\n",
      "Train - Loss: 0.0441 | Acc: 98.53%\n",
      "Valid - Loss: 0.7938 | Acc: 79.30%\n",
      "--------------------------------------------------\n",
      "Epoch [43/100]\n",
      "Train - Loss: 0.0587 | Acc: 97.82%\n",
      "Valid - Loss: 0.8288 | Acc: 78.72%\n",
      "--------------------------------------------------\n",
      "Epoch [44/100]\n",
      "Train - Loss: 0.0582 | Acc: 97.62%\n",
      "Valid - Loss: 0.7162 | Acc: 82.40%\n",
      "--------------------------------------------------\n",
      "Epoch [45/100]\n",
      "Train - Loss: 0.1616 | Acc: 94.20%\n",
      "Valid - Loss: 0.8336 | Acc: 73.31%\n",
      "--------------------------------------------------\n",
      "Epoch [46/100]\n",
      "Train - Loss: 0.0677 | Acc: 97.82%\n",
      "Valid - Loss: 0.6245 | Acc: 81.04%\n",
      "--------------------------------------------------\n",
      "Epoch [47/100]\n",
      "Train - Loss: 0.0405 | Acc: 98.72%\n",
      "Valid - Loss: 0.6731 | Acc: 80.08%\n",
      "--------------------------------------------------\n",
      "Epoch [48/100]\n",
      "Train - Loss: 0.0260 | Acc: 99.21%\n",
      "Valid - Loss: 0.6965 | Acc: 80.37%\n",
      "--------------------------------------------------\n",
      "Epoch [49/100]\n",
      "Train - Loss: 0.0232 | Acc: 99.32%\n",
      "Valid - Loss: 0.6521 | Acc: 82.01%\n",
      "--------------------------------------------------\n",
      "Epoch [50/100]\n",
      "Train - Loss: 0.0181 | Acc: 99.52%\n",
      "Valid - Loss: 0.5977 | Acc: 83.66%\n",
      "--------------------------------------------------\n",
      "Epoch [51/100]\n",
      "Train - Loss: 0.0202 | Acc: 99.40%\n",
      "Valid - Loss: 0.7551 | Acc: 79.98%\n",
      "--------------------------------------------------\n",
      "Epoch [52/100]\n",
      "Train - Loss: 0.0138 | Acc: 99.65%\n",
      "Valid - Loss: 0.5445 | Acc: 86.27%\n",
      "--------------------------------------------------\n",
      "Epoch [53/100]\n",
      "Train - Loss: 0.0167 | Acc: 99.48%\n",
      "Valid - Loss: 0.7791 | Acc: 80.37%\n",
      "--------------------------------------------------\n",
      "Epoch [54/100]\n",
      "Train - Loss: 0.0116 | Acc: 99.65%\n",
      "Valid - Loss: 0.6329 | Acc: 84.72%\n",
      "--------------------------------------------------\n",
      "Epoch [55/100]\n",
      "Train - Loss: 0.0130 | Acc: 99.59%\n",
      "Valid - Loss: 0.5318 | Acc: 87.33%\n",
      "--------------------------------------------------\n",
      "Epoch [56/100]\n",
      "Train - Loss: 0.0147 | Acc: 99.54%\n",
      "Valid - Loss: 0.8395 | Acc: 79.98%\n",
      "--------------------------------------------------\n",
      "Epoch [57/100]\n",
      "Train - Loss: 0.0070 | Acc: 99.90%\n",
      "Valid - Loss: 0.7172 | Acc: 83.66%\n",
      "--------------------------------------------------\n",
      "Epoch [58/100]\n",
      "Train - Loss: 0.0070 | Acc: 99.88%\n",
      "Valid - Loss: 0.9412 | Acc: 77.66%\n",
      "--------------------------------------------------\n",
      "Epoch [59/100]\n",
      "Train - Loss: 0.0066 | Acc: 99.83%\n",
      "Valid - Loss: 0.6546 | Acc: 85.11%\n",
      "--------------------------------------------------\n",
      "Epoch [60/100]\n",
      "Train - Loss: 0.0111 | Acc: 99.65%\n",
      "Valid - Loss: 0.5238 | Acc: 88.78%\n",
      "--------------------------------------------------\n",
      "Epoch [61/100]\n",
      "Train - Loss: 0.0157 | Acc: 99.46%\n",
      "Valid - Loss: 1.5718 | Acc: 65.09%\n",
      "--------------------------------------------------\n",
      "Epoch [62/100]\n",
      "Train - Loss: 0.0254 | Acc: 99.09%\n",
      "Valid - Loss: 0.9134 | Acc: 80.95%\n",
      "--------------------------------------------------\n",
      "Epoch [63/100]\n",
      "Train - Loss: 0.1390 | Acc: 96.25%\n",
      "Valid - Loss: 0.5715 | Acc: 85.78%\n",
      "--------------------------------------------------\n",
      "Epoch [64/100]\n",
      "Train - Loss: 0.1901 | Acc: 94.57%\n",
      "Valid - Loss: 0.6874 | Acc: 78.24%\n",
      "--------------------------------------------------\n",
      "Epoch [65/100]\n",
      "Train - Loss: 0.0685 | Acc: 97.53%\n",
      "Valid - Loss: 0.7134 | Acc: 79.59%\n",
      "--------------------------------------------------\n",
      "Epoch [66/100]\n",
      "Train - Loss: 0.0499 | Acc: 98.07%\n",
      "Valid - Loss: 0.3177 | Acc: 90.52%\n",
      "--------------------------------------------------\n",
      "Epoch [67/100]\n",
      "Train - Loss: 0.0604 | Acc: 97.68%\n",
      "Valid - Loss: 0.4205 | Acc: 87.62%\n",
      "--------------------------------------------------\n",
      "Epoch [68/100]\n",
      "Train - Loss: 0.0340 | Acc: 98.80%\n",
      "Valid - Loss: 0.6019 | Acc: 81.53%\n",
      "--------------------------------------------------\n",
      "Epoch [69/100]\n",
      "Train - Loss: 0.0138 | Acc: 99.75%\n",
      "Valid - Loss: 0.6440 | Acc: 80.95%\n",
      "--------------------------------------------------\n",
      "Epoch [70/100]\n",
      "Train - Loss: 0.0082 | Acc: 99.88%\n",
      "Valid - Loss: 0.5965 | Acc: 82.40%\n",
      "--------------------------------------------------\n",
      "Epoch [71/100]\n",
      "Train - Loss: 0.0069 | Acc: 99.92%\n",
      "Valid - Loss: 0.6507 | Acc: 81.72%\n",
      "--------------------------------------------------\n",
      "Epoch [72/100]\n",
      "Train - Loss: 0.0061 | Acc: 99.94%\n",
      "Valid - Loss: 0.6512 | Acc: 82.01%\n",
      "--------------------------------------------------\n",
      "Epoch [73/100]\n",
      "Train - Loss: 0.0057 | Acc: 99.92%\n",
      "Valid - Loss: 0.6801 | Acc: 82.11%\n",
      "--------------------------------------------------\n",
      "Epoch [74/100]\n",
      "Train - Loss: 0.0049 | Acc: 99.94%\n",
      "Valid - Loss: 0.7199 | Acc: 81.43%\n",
      "--------------------------------------------------\n",
      "Epoch [75/100]\n",
      "Train - Loss: 0.0048 | Acc: 99.94%\n",
      "Valid - Loss: 0.6828 | Acc: 82.69%\n",
      "--------------------------------------------------\n",
      "Epoch [76/100]\n",
      "Train - Loss: 0.0042 | Acc: 99.92%\n",
      "Valid - Loss: 0.7083 | Acc: 82.30%\n",
      "--------------------------------------------------\n",
      "Epoch [77/100]\n",
      "Train - Loss: 0.0041 | Acc: 99.92%\n",
      "Valid - Loss: 0.7236 | Acc: 82.59%\n",
      "--------------------------------------------------\n",
      "Epoch [78/100]\n",
      "Train - Loss: 0.0033 | Acc: 99.96%\n",
      "Valid - Loss: 0.7465 | Acc: 82.50%\n",
      "--------------------------------------------------\n",
      "Epoch [79/100]\n",
      "Train - Loss: 0.0030 | Acc: 99.96%\n",
      "Valid - Loss: 0.7208 | Acc: 83.27%\n",
      "--------------------------------------------------\n",
      "Epoch [80/100]\n",
      "Train - Loss: 0.0045 | Acc: 99.92%\n",
      "Valid - Loss: 0.7271 | Acc: 83.08%\n",
      "--------------------------------------------------\n",
      "Epoch [81/100]\n",
      "Train - Loss: 0.0605 | Acc: 98.22%\n",
      "Valid - Loss: 1.0691 | Acc: 76.89%\n",
      "--------------------------------------------------\n",
      "Epoch [82/100]\n",
      "Train - Loss: 0.0279 | Acc: 99.13%\n",
      "Valid - Loss: 0.8590 | Acc: 81.72%\n",
      "--------------------------------------------------\n",
      "Epoch [83/100]\n",
      "Train - Loss: 0.0576 | Acc: 98.18%\n",
      "Valid - Loss: 0.6128 | Acc: 84.82%\n",
      "--------------------------------------------------\n",
      "Epoch [84/100]\n",
      "Train - Loss: 0.0265 | Acc: 99.11%\n",
      "Valid - Loss: 0.6148 | Acc: 84.04%\n",
      "--------------------------------------------------\n",
      "Epoch [85/100]\n",
      "Train - Loss: 0.0152 | Acc: 99.50%\n",
      "Valid - Loss: 1.1609 | Acc: 68.47%\n",
      "--------------------------------------------------\n",
      "Epoch [86/100]\n",
      "Train - Loss: 0.0101 | Acc: 99.77%\n",
      "Valid - Loss: 0.6014 | Acc: 85.49%\n",
      "--------------------------------------------------\n",
      "Epoch [87/100]\n",
      "Train - Loss: 0.0069 | Acc: 99.83%\n",
      "Valid - Loss: 0.9322 | Acc: 75.24%\n",
      "--------------------------------------------------\n",
      "Epoch [88/100]\n",
      "Train - Loss: 0.0050 | Acc: 99.88%\n",
      "Valid - Loss: 0.5990 | Acc: 85.88%\n",
      "--------------------------------------------------\n",
      "Epoch [89/100]\n",
      "Train - Loss: 0.0039 | Acc: 99.94%\n",
      "Valid - Loss: 0.7192 | Acc: 83.17%\n",
      "--------------------------------------------------\n",
      "Epoch [90/100]\n",
      "Train - Loss: 0.0031 | Acc: 99.96%\n",
      "Valid - Loss: 0.7297 | Acc: 83.08%\n",
      "--------------------------------------------------\n",
      "Epoch [91/100]\n",
      "Train - Loss: 0.0029 | Acc: 99.96%\n",
      "Valid - Loss: 0.7304 | Acc: 83.37%\n",
      "--------------------------------------------------\n",
      "Epoch [92/100]\n",
      "Train - Loss: 0.0027 | Acc: 99.96%\n",
      "Valid - Loss: 0.7534 | Acc: 82.88%\n",
      "--------------------------------------------------\n",
      "Epoch [93/100]\n",
      "Train - Loss: 0.0026 | Acc: 99.96%\n",
      "Valid - Loss: 0.7686 | Acc: 82.88%\n",
      "--------------------------------------------------\n",
      "Epoch [94/100]\n",
      "Train - Loss: 0.0023 | Acc: 99.98%\n",
      "Valid - Loss: 0.7730 | Acc: 83.08%\n",
      "--------------------------------------------------\n",
      "Epoch [95/100]\n",
      "Train - Loss: 0.0024 | Acc: 99.98%\n",
      "Valid - Loss: 0.7628 | Acc: 83.75%\n",
      "--------------------------------------------------\n",
      "Epoch [96/100]\n",
      "Train - Loss: 0.0114 | Acc: 99.52%\n",
      "Valid - Loss: 0.2185 | Acc: 92.46%\n",
      "--------------------------------------------------\n",
      "Epoch [97/100]\n",
      "Train - Loss: 0.2846 | Acc: 92.56%\n",
      "Valid - Loss: 0.3323 | Acc: 89.26%\n",
      "--------------------------------------------------\n",
      "Epoch [98/100]\n",
      "Train - Loss: 0.0668 | Acc: 97.37%\n",
      "Valid - Loss: 0.7356 | Acc: 80.66%\n",
      "--------------------------------------------------\n",
      "Epoch [99/100]\n",
      "Train - Loss: 0.0257 | Acc: 99.09%\n",
      "Valid - Loss: 0.4311 | Acc: 87.72%\n",
      "--------------------------------------------------\n",
      "Epoch [100/100]\n",
      "Train - Loss: 0.0085 | Acc: 99.85%\n",
      "Valid - Loss: 0.4531 | Acc: 87.23%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Training loop with validation\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, n_epochs, device):\n",
    "    best_val_acc = 0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # ---- Training phase ----\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            # Move to device\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * x.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_correct += (predicted == y).sum().item()\n",
    "            train_total += y.size(0)\n",
    "\n",
    "        # Calculate training metrics\n",
    "        epoch_train_loss = train_loss / train_total\n",
    "        epoch_train_acc = 100.0 * train_correct / train_total\n",
    "        \n",
    "        # ---- Validation phase ----\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                outputs = model(x)\n",
    "                loss = criterion(outputs, y)\n",
    "                \n",
    "                val_loss += loss.item() * x.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == y).sum().item()\n",
    "                val_total += y.size(0)\n",
    "        \n",
    "        # Calculate validation metrics\n",
    "        epoch_val_loss = val_loss / val_total\n",
    "        epoch_val_acc = 100.0 * val_correct / val_total\n",
    "        \n",
    "        # Store metrics\n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        history['train_acc'].append(epoch_train_acc)\n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "        history['val_acc'].append(epoch_val_acc)\n",
    "        \n",
    "        # Save best model\n",
    "        if epoch_val_acc > best_val_acc:\n",
    "            best_val_acc = epoch_val_acc\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_acc': best_val_acc,\n",
    "            }, 'best_model.pt')\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Epoch [{epoch+1}/{n_epochs}]\")\n",
    "        print(f\"Train - Loss: {epoch_train_loss:.4f} | Acc: {epoch_train_acc:.2f}%\")\n",
    "        print(f\"Valid - Loss: {epoch_val_loss:.4f} | Acc: {epoch_val_acc:.2f}%\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Usage\n",
    "n_epochs = 100\n",
    "history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_dataloader,\n",
    "    val_loader=val_dataloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    n_epochs=n_epochs,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883b888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history['train_acc'], label='Train Acc')\n",
    "plt.plot(history['val_acc'], label='Val Acc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
